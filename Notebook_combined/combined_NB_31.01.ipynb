{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1d0e2ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "555ffb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to form the table\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# To load and save files\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "from scipy import interpolate\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.optimize import curve_fit\n",
    "import scipy.io as sio\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pylab\n",
    "from pylab import *\n",
    "from matplotlib.pyplot import show \n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.widgets import TextBox\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.image as mpimg \n",
    "import matplotlib.colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a6fe3998",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## set personal saving/ retrieving configuration\n",
    "\n",
    "## Loading data\n",
    "load_data=0\n",
    "load_new_neurons=0 # set to 1 to load, else retrieved\n",
    "# define where emg recording is retrieved from (matlab file)\n",
    "location_mat_file='/Volumes/Extreme_SSD/Projectome_Estimation/filtered_objects/RCPoints_MR012_subset.mat'\n",
    "# define simulation is retrieved from (csv file)\n",
    "location_simulation_file='/Volumes/Extreme_SSD/Projectome_finder/data/senn_single_pulse'\n",
    "## Set subject and lead position\n",
    "subject='MR012'\n",
    "lead='GO2'\n",
    "\n",
    "\n",
    "## Plotting\n",
    "save_plot=0 # set to 1 to automatically save all the plots\n",
    "#define location where plots should be saved\n",
    "# location_save_plots=f'Volumes/Extreme_SSD/Projectome_finder/plots/{subject}/' #somehow doesnt work here\n",
    "location_save_plots=f'/Users/nealarohner/Desktop/Projectome_Finder/code/Neala_Master_Thesis/plots/{subject}/'\n",
    "os.makedirs(location_save_plots,exist_ok=True)\n",
    "#Define where images used in the plot are saved\n",
    "location_image=\"/Volumes/Extreme_SSD/Projectome_finder/Images_for_plot\"\n",
    "\n",
    "\n",
    "\n",
    "## if a new dataset should be loaded else dataset will be retrieved\n",
    "#define location where data should be saved\n",
    "location_data_dump=f'/Volumes/Extreme_SSD/Projectome_finder/CSV_and_pickle/{subject}/'\n",
    "os.makedirs(location_data_dump,exist_ok=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5520fb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_electrodes_for_roots=pd.read_csv(location_data_dump+'df_electrodes_for_roots.csv')\n",
    "electrodes_from_listing=list(df_electrodes_for_roots[\"electrode_name\"])\n",
    "   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "caa8884f",
   "metadata": {},
   "source": [
    "## Save figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7aec36e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_figure(folder_name, data_file,location_save_plots=location_save_plots ):\n",
    "    \"\"\"\n",
    "    A function to get the number for the heatmap by by taking the  electric current at the point where afferent recruitment reaches 100%.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    folder_name\n",
    "        which folder should it be saved to? eg. recruitment/roots\n",
    "    data_file\n",
    "        name of plot\n",
    "    location_save_plots\n",
    "        location where plots should be save, set in the beginning\n",
    "    \"\"\"\n",
    "    data_folder = location_save_plots\n",
    "    save_folder = os.path.join(data_folder,folder_name)\n",
    "    os.makedirs(save_folder,exist_ok=True)\n",
    "    data_file_path = os.path.join(save_folder,data_file)\n",
    "    plt.savefig(data_file_path, transparent = \"False\",  \n",
    "    facecolor='w', \n",
    "    bbox_inches='tight'\n",
    "            )\n",
    "    print(f\" figure saved: {data_file_path} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8933f23",
   "metadata": {},
   "source": [
    "# Muscles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75d9946",
   "metadata": {},
   "source": [
    "## Load new data and create a tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28369168",
   "metadata": {},
   "source": [
    "### Loading an RC from Matlab into Python\n",
    "We load a previously saved RCpoints from Matlab into point for later manipulation as tensor.\n",
    "\n",
    "**structure of a RCPoint**\n",
    "* Lead -> implanted lead\n",
    "* Position -> repositioning ID from during surgery\n",
    "* Electrode -> 0-based electrode numbering\n",
    "* Amp -> stimulation amp\n",
    "* EMGs_filt -> filtered EMG responses\n",
    "* NormConsts -> normalization constants that were used based on maximal responses\n",
    "* muscle -> median of peak-to-peak of responses (real value if only one pulse at this amplitude)\n",
    "* muscle_all -> all peak-to-peaks for the responses at same amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b3f8a920",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d447894c",
   "metadata": {},
   "source": [
    "Loading the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "39310d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_data:\n",
    "    mat_contents = sio.loadmat(location_mat_file,squeeze_me=True)\n",
    "    print(type(mat_contents['subsetRC']))\n",
    "    subset_array=mat_contents['subsetRC']\n",
    "    n_cells=len(subset_array)\n",
    "\n",
    "    # Cells are trials\n",
    "    n_trials=n_cells\n",
    "\n",
    "    # We load 1 cell and go all the way to get the key names.\n",
    "    i_cell = 0 \n",
    "    cell_i=subset_array[i_cell]\n",
    "    keys_cell_i = cell_i.dtype.names\n",
    "    print(\"keys_cell_i\",keys_cell_i)\n",
    "    n_keys_cell_i=len(keys_cell_i)\n",
    "    print(\"n_keys_cell_i\",n_keys_cell_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7a20bade",
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_data:    \n",
    "    # Let's declare the keys independently so that it becomes easier to go through them\n",
    "    key_lead=keys_cell_i[0]\n",
    "    key_position=keys_cell_i[1]\n",
    "    key_electrode=keys_cell_i[2]\n",
    "    key_amplitude=keys_cell_i[3]\n",
    "    key_emg_time_series=keys_cell_i[4]\n",
    "    key_normalization_constants_list=keys_cell_i[5]\n",
    "    indices_median_peak2peak=np.arange(6,38,2)\n",
    "    indices_median_peak2peak=indices_median_peak2peak.astype(int)\n",
    "    keys_median_peak2peak_muscle=[keys_cell_i[index] for index in indices_median_peak2peak]\n",
    "    indices_all_peak2peak=np.arange(7,39,2)\n",
    "    indices_all_peak2peak=indices_all_peak2peak.astype(int)\n",
    "    keys_all_peak2peak_muscle=[keys_cell_i[index] for index in indices_all_peak2peak]\n",
    "    indices_movements_peak2peak=np.arange(38,46,1)\n",
    "    indices_movements_peak2peak=indices_movements_peak2peak.astype(int)\n",
    "    keys_movements_peak2peak_muscle=[keys_cell_i[index] for index in indices_movements_peak2peak]\n",
    "    n_movements_peak2peak_muscle=len(keys_movements_peak2peak_muscle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "24aeea5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_data:\n",
    "    # Now let's open up a EMG time serie struct array and take the keys\n",
    "    emg_filt_time_series_cell_i=cell_i[key_emg_time_series].item()\n",
    "    keys_emg_filt_time_serie_cell_i = emg_filt_time_series_cell_i.dtype.names\n",
    "    print(\"keys_emg_filt_time_serie_cell_i\",keys_emg_filt_time_serie_cell_i)\n",
    "    n_keys_emg_filt_time_serie_cell_i=len(keys_emg_filt_time_serie_cell_i)\n",
    "    print(\"n_keys_emg_filt_time_serie_cell_i\",n_keys_emg_filt_time_serie_cell_i)\n",
    "\n",
    "    # Now let's open up a normalization constants serie struct array and take the keys\n",
    "    normalization_constants_list_cell_i=cell_i[key_normalization_constants_list].item()\n",
    "    keys_normalization_constants_list_cell_i = normalization_constants_list_cell_i.dtype.names\n",
    "    print(\"keys_normalization_constants_list_cell_i\",keys_normalization_constants_list_cell_i)\n",
    "    n_keys_normalization_constants_list_cell_i=len(keys_normalization_constants_list_cell_i)\n",
    "    print(\"n_keys_emg_filt_time_serie_cell_i\",n_keys_normalization_constants_list_cell_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42107d1",
   "metadata": {},
   "source": [
    "The keys from the EMG filt time serie, the list of the normalization constants and the keys_median_peak2peak_muscle seem to be the list of muscles (16 muscles) and they are identical. The keys_all_peak2peak_muscle have an \\_all appendend to each muscle name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c980436d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_data:\n",
    "    # Getting a specific EMG filt time serie\n",
    "    j_muscle_EMG_filt_time_serie_cell_i=0\n",
    "    key_muscle_j_EMG_filt_time_serie_cell_i=keys_emg_filt_time_serie_cell_i[j_muscle_EMG_filt_time_serie_cell_i]\n",
    "    print(\"key_muscle_j_EMG_filt_time_serie_cell_i\",key_muscle_j_EMG_filt_time_serie_cell_i)\n",
    "    muscle_j_EMG_filt_time_serie_cell_i=emg_filt_time_series_cell_i[key_muscle_j_EMG_filt_time_serie_cell_i].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f8e0cc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_data:\n",
    "    lead_cell_i=cell_i[key_lead].item()\n",
    "    position_cell_i=cell_i[key_position].item()\n",
    "    electrode_cell_i=cell_i[key_electrode].item()\n",
    "    amplitude_cell_i=cell_i[key_amplitude].item()\n",
    "    key_muscle_j_EMG_filt_time_serie_cell_i=key_muscle_j_EMG_filt_time_serie_cell_i\n",
    "    normalization_constant_muscle_j_cell_i=normalization_constants_list_cell_i[key_muscle_j_EMG_filt_time_serie_cell_i].item()\n",
    "    title_string=lead_cell_i+' - Position: '+str(position_cell_i)+' - Electrode: '+str(electrode_cell_i)+' - Amplitude: '+str(amplitude_cell_i)\n",
    "    label_string=\"Muscle \"+key_muscle_j_EMG_filt_time_serie_cell_i+' - normalized with:'+\"{:10.2f}\".format(normalization_constant_muscle_j_cell_i)\n",
    "    fig = plt.figure(figsize=(7,7))\n",
    "    plt.plot(muscle_j_EMG_filt_time_serie_cell_i,label=label_string)\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Timepoint\")\n",
    "    plt.ylabel(\"Filtered EMG\")\n",
    "    plt.title(title_string)\n",
    "    plt.grid()\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "077c429c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_data:\n",
    "    # Getting the peak to peak saved values for all muscles\n",
    "    median_peak2peak_muscles_cell_i=cell_i[keys_median_peak2peak_muscle]\n",
    "    median_peak2peak_muscle_j_cell_i=median_peak2peak_muscles_cell_i[key_muscle_j_EMG_filt_time_serie_cell_i].item()\n",
    "\n",
    "    # Getting the all peak to peak for this particular muscle\n",
    "    key_muscle_j_EMG_filt_time_serie_cell_i_all=key_muscle_j_EMG_filt_time_serie_cell_i+\"_all\"\n",
    "    all_peak2peak_muscles_cell_i=cell_i[keys_all_peak2peak_muscle]\n",
    "    all_peak2peak_muscle_j_cell_i=all_peak2peak_muscles_cell_i[key_muscle_j_EMG_filt_time_serie_cell_i_all].item()\n",
    "\n",
    "    # For the movements let us keep them everywhere since we have little info about them so far\n",
    "    movements_peak2peak_muscle_cell_i=cell_i[keys_movements_peak2peak_muscle]\n",
    "    for k_movement in range(n_movements_peak2peak_muscle):\n",
    "        key_movement_k_peak2peak_cell_i=keys_movements_peak2peak_muscle[k_movement]\n",
    "        movement_k_peak2peak_cell_i=movements_peak2peak_muscle_cell_i[key_movement_k_peak2peak_cell_i].item()\n",
    "        print(key_movement_k_peak2peak_cell_i,movement_k_peak2peak_cell_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df81b44d",
   "metadata": {},
   "source": [
    "### Data frame construction\n",
    "\n",
    "Now let us build a dataframe with all the data for later processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d70aa5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_data:\n",
    "    verbose=1\n",
    "    subject = 'MR012'\n",
    "    n_rows_to_display = 5\n",
    "    pd.set_option('display.max_rows', n_rows_to_display)\n",
    "    print(f\"n_keys_emg_filt_time_serie_cell_i: {n_keys_emg_filt_time_serie_cell_i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "24f76c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_data:\n",
    "    list_elec_config_dfs = []\n",
    "    if verbose:\n",
    "        print(\"Loading data of subject:\",subject)\n",
    "    for i_cell in range(n_cells):\n",
    "        if verbose:\n",
    "            print(\"Loading cell: \",i_cell)\n",
    "        cell_i=subset_array[i_cell]\n",
    "        keys_cell_i = cell_i.dtype.names\n",
    "        if verbose>2:\n",
    "            print(\"keys_cell_i\",keys_cell_i)\n",
    "        n_keys_cell_i=len(keys_cell_i)\n",
    "        if verbose>2:\n",
    "            print(\"n_keys_cell_i\",n_keys_cell_i)\n",
    "        # Getting the info with the previously extracted keys\n",
    "        lead_cell_i=cell_i[key_lead].item()\n",
    "        position_cell_i=cell_i[key_position].item()\n",
    "        electrode_cell_i=cell_i[key_electrode].item()\n",
    "        amplitude_cell_i=cell_i[key_amplitude].item()\n",
    "        # Lists\n",
    "        median_peak2peak_muscles_cell_i=cell_i[keys_median_peak2peak_muscle]\n",
    "        all_peak2peak_muscles_cell_i=cell_i[keys_all_peak2peak_muscle]\n",
    "        movements_peak2peak_muscle_cell_i=cell_i[keys_movements_peak2peak_muscle]\n",
    "        # Structured arrays with arrays inside\n",
    "        emg_filt_time_series_cell_i=cell_i[key_emg_time_series].item()\n",
    "        normalization_constants_list_cell_i=cell_i[key_normalization_constants_list].item()\n",
    "        # Getting time series\n",
    "        for j_muscle_EMG_filt_time_serie_cell_i in range(n_keys_emg_filt_time_serie_cell_i):\n",
    "            key_muscle_j_EMG_filt_time_serie_cell_i=keys_emg_filt_time_serie_cell_i[j_muscle_EMG_filt_time_serie_cell_i]\n",
    "            key_muscle_j_EMG_filt_time_serie_cell_i_all=key_muscle_j_EMG_filt_time_serie_cell_i+\"_all\"\n",
    "            median_peak2peak_muscle_j_cell_i=median_peak2peak_muscles_cell_i[key_muscle_j_EMG_filt_time_serie_cell_i].item()\n",
    "            all_peak2peak_muscle_j_cell_i=all_peak2peak_muscles_cell_i[key_muscle_j_EMG_filt_time_serie_cell_i_all].item()\n",
    "            # if verbose: \n",
    "            #     print(\"Muscle\",key_muscle_j_EMG_filt_time_serie_cell_i)\n",
    "            muscle_j_EMG_filt_time_serie_cell_i=emg_filt_time_series_cell_i[key_muscle_j_EMG_filt_time_serie_cell_i].item()\n",
    "            n_time_points_trial=len(muscle_j_EMG_filt_time_serie_cell_i)\n",
    "            if n_time_points_trial!=1000:\n",
    "                print(key_muscle_j_EMG_filt_time_serie_cell_i,n_time_points_trial )\n",
    "            \n",
    "            normalization_constant_muscle_j_cell_i=normalization_constants_list_cell_i[key_muscle_j_EMG_filt_time_serie_cell_i].item()\n",
    "            # Creating the dataframe\n",
    "            df_trial_muscle_and_other_i_data = pd.DataFrame(data=[[muscle_j_EMG_filt_time_serie_cell_i]],columns=[key_emg_time_series])\n",
    "            df_trial_muscle_and_other_i_data['Time_points'] = n_time_points_trial\n",
    "            df_trial_muscle_and_other_i_data['Muscle'] = key_muscle_j_EMG_filt_time_serie_cell_i\n",
    "            df_trial_muscle_and_other_i_data['Elec_config'] = electrode_cell_i\n",
    "            df_trial_muscle_and_other_i_data['Subject'] = subject\n",
    "            df_trial_muscle_and_other_i_data['Amplitudes'] = amplitude_cell_i\n",
    "            df_trial_muscle_and_other_i_data['Lead'] = lead_cell_i\n",
    "            df_trial_muscle_and_other_i_data['Position'] = position_cell_i\n",
    "            df_trial_muscle_and_other_i_data['Normalization_Constant'] = normalization_constant_muscle_j_cell_i\n",
    "            df_trial_muscle_and_other_i_data['Median_Peak2Peak'] = median_peak2peak_muscle_j_cell_i\n",
    "            df_trial_muscle_and_other_i_data['All_Peak2Peak'] = [all_peak2peak_muscle_j_cell_i]\n",
    "            # filling the movements\n",
    "            for k_movement in range(n_movements_peak2peak_muscle):\n",
    "                key_movement_k_peak2peak_cell_i=keys_movements_peak2peak_muscle[k_movement]\n",
    "                movement_k_peak2peak_cell_i=movements_peak2peak_muscle_cell_i[key_movement_k_peak2peak_cell_i].item()\n",
    "                df_trial_muscle_and_other_i_data[key_movement_k_peak2peak_cell_i] = movement_k_peak2peak_cell_i\n",
    "                if verbose>1:\n",
    "                    print(key_movement_k_peak2peak_cell_i,movement_k_peak2peak_cell_i)\n",
    "            list_elec_config_dfs.append(df_trial_muscle_and_other_i_data)\n",
    "    if len(list_elec_config_dfs)>0:\n",
    "        df_subject = pd.concat(list_elec_config_dfs, ignore_index=True)\n",
    "        df_subject.reset_index(inplace=True)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d5d6ad11",
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_data:\n",
    "    print(df_subject)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab03024",
   "metadata": {},
   "source": [
    "### Save the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "da66a82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_data:\n",
    "    mt_electrodes=pd.DataFrame(df_subject['Elec_config'].unique(), columns=[\"elec_name\"])  #Elec01_, Elec02_, Elec03_, \n",
    "    mt_muscles=pd.DataFrame(df_subject['Muscle'].unique(), columns=[\"muscle_name\"]) #LVlat, LST, ..\n",
    "    unique_amplitudes=pd.DataFrame(df_subject['Amplitudes'].unique(), columns=[\"amplitude_name\"])\n",
    "    \n",
    "\n",
    "    \n",
    "    mt_electrodes.to_csv(location_data_dump+'mt_electrodes.csv')\n",
    "    mt_muscles.to_csv(location_data_dump+'mt_muscles.csv')\n",
    "    unique_amplitudes.to_csv(location_data_dump+'unique_amplitudes.csv')\n",
    "    df_subject.to_csv(location_data_dump+'df_subject.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c845a39f",
   "metadata": {},
   "source": [
    "### Create tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f6376797",
   "metadata": {},
   "outputs": [],
   "source": [
    "#device =  \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed08016",
   "metadata": {},
   "source": [
    "Max reps evt not used in the future, better to take the mean already, but also think on how to make it automatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f2ba1cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def unique(list1):\n",
    "#     x = np.array(list1)\n",
    "#     print(np.unique(x))\n",
    "\n",
    "# max_reps=unique(max(reps))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfed295",
   "metadata": {},
   "source": [
    "#### Create filtered data tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f56669",
   "metadata": {},
   "source": [
    "Manually adjustable if tensors should be created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6a0f6959",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_tensor=load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "0ead39b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#electrodes\n",
    "#muscles\n",
    "#amplitudes\n",
    "#max_reps\n",
    "#filtered EMG\n",
    "if create_tensor:\n",
    "    max_reps=39 # see notebook 6\n",
    "    time_points=1000\n",
    "\n",
    "    filtered_data_to_tensor=torch.ones(len(mt_electrodes['elec_name']),len(mt_muscles['muscle_name']),len(unique_amplitudes),max_reps,time_points)\n",
    "    filtered_data_to_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "070b94fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make it work with df\n",
    "if create_tensor:\n",
    "    for elec_i in range (len(mt_electrodes['elec_name'])) : #loop through all the elecs\n",
    "        for muscle_i in range (len(mt_muscles['muscle_name'])): # loop through all the muscles\n",
    "            amp_index=0\n",
    "            data_amp_index=0\n",
    "            print(f\"elec: {elec_i} muscle:{muscle_i}\")\n",
    "            for amp_in_unique_amp in unique_amplitudes: # loop through all the amplitudes\n",
    "                print(\"#####################################################\")\n",
    "                print(f\"searching for data for amplitude {amp_in_unique_amp}\")\n",
    "                reps=0\n",
    "\n",
    "                #compare length, in order to stop after max amplitude of a combiantion\n",
    "                if data_amp_index < len(df_subject[(df_subject[\"Elec_config\"]==elec_i)&(df_subject[\"Muscle\"]== mt_muscles['muscle_name'][muscle_i] )][\"Amplitudes\"]): \n",
    "                    #Check for which amplitudes there is data\n",
    "                    print(\"passed checkpoint, now check if aplitudes match\")\n",
    "                    data_amp=round(df_subject[(df_subject[\"Elec_config\"]==elec_i)&(df_subject[\"Muscle\"]== mt_muscles['muscle_name'][muscle_i] )].reset_index().iloc[data_amp_index][\"Amplitudes\"], 2)\n",
    "                    print(f\"comparing unique: {amp_in_unique_amp} with data amp: {data_amp}\")\n",
    "                    if data_amp==amp_in_unique_amp:                        \n",
    "                        #Fill the single reps with data\n",
    "                        print(\"found a suiting amplitude\")\n",
    "                        print(\"Now how many reps\")\n",
    "                        checking_reps=df_subject[(df_subject[\"Elec_config\"]==elec_i)&(df_subject[\"Muscle\"]== mt_muscles['muscle_name'][muscle_i] )&(round(df_subject[\"Amplitudes\"],2)== data_amp )][\"Time_points\"].item()\n",
    "\n",
    "                        if checking_reps==1000:\n",
    "                            print(\"only one trial\")\n",
    "                            # Fill data\n",
    "                            filtered_data_to_tensor[elec_i, muscle_i, amp_index,reps,:]=torch.tensor(df_subject[(df_subject[\"Elec_config\"]==elec_i)&(df_subject[\"Muscle\"]== mt_muscles['muscle_name'][muscle_i])&(round(df_subject[\"Amplitudes\"], 2)== amp_in_unique_amp)][\"EMGs_filt\"].item())\n",
    "                            # Fill left over with nan values\n",
    "                            reps+=1 \n",
    "                            filtered_data_to_tensor[elec_i, muscle_i, amp_index,reps:,:]=torch.zeros((len(filtered_data_to_tensor[elec_i, muscle_i, amp_index,reps:,0]),time_points)).float()\n",
    "                            filtered_data_to_tensor[filtered_data_to_tensor==0]= float('nan') #didn't find torch.nan function\n",
    "                        #Fill the multiple reps with data\n",
    "                        else:\n",
    "                            while reps<checking_reps:\n",
    "                                print(\"going through the while loop\")\n",
    "                                print(\" fill data\")\n",
    "                                filtered_data_to_tensor[elec_i, muscle_i, amp_index,reps,:]=torch.tensor(df_subject[(df_subject[\"Elec_config\"]==elec_i)&(df_subject[\"Muscle\"]== mt_muscles['muscle_name'][muscle_i])&(round(df_subject[\"Amplitudes\"], 2)== amp_in_unique_amp)][\"EMGs_filt\"].item()[reps])\n",
    "                                reps+=1\n",
    "\n",
    "                            # Fill left over reps with nan\n",
    "                            else: \n",
    "                                print(\"finished the while loop\")\n",
    "                                if checking_reps<max_reps:\n",
    "                                    filtered_data_to_tensor[elec_i, muscle_i, amp_index,reps:,:]=torch.zeros((len(filtered_data_to_tensor[elec_i, muscle_i, amp_index,reps:,0]),time_points)).float()\n",
    "                                    filtered_data_to_tensor[filtered_data_to_tensor==0]= float('nan') #didn't find torch.nan function\n",
    "                        \n",
    "                        #increase the amplitude index by one\n",
    "                        data_amp_index+=1\n",
    "                        \n",
    "                    #Fill the amplitudes without data with 'nan'\n",
    "                    else:\n",
    "                        print(f\"No match for {amp_in_unique_amp} fill with nan\")\n",
    "                        filtered_data_to_tensor[elec_i, muscle_i, amp_index,:,:]=torch.zeros((max_reps,time_points)).float()\n",
    "                        filtered_data_to_tensor[filtered_data_to_tensor==0]= float('nan') #didn't find torch.nan function\n",
    "                    \n",
    "                    #increase the amplitude index by one\n",
    "                    amp_index+=1 \n",
    "\n",
    "                else:\n",
    "                    print(f\"No more data for this combination  fill all with nan\")\n",
    "                    filtered_data_to_tensor[elec_i, muscle_i, amp_index,:,:]=torch.zeros((max_reps,time_points)).float()\n",
    "                    filtered_data_to_tensor[filtered_data_to_tensor==0]= float('nan') #didn't find torch.nan function\n",
    "                \n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd864336",
   "metadata": {},
   "source": [
    "#### Create peak to peak values tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "95ba7f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#electrodes\n",
    "#muscles\n",
    "#amplitudes\n",
    "#max_reps\n",
    "#peak to peak value\n",
    "if create_tensor:\n",
    "    max_reps=39 # see notebook 6\n",
    "    peak_to_peak_value=1\n",
    "\n",
    "\n",
    "    peak2peak_data_to_tensor=torch.ones(len(mt_electrodes['elec_name']),len(mt_muscles['muscle_name']),len(unique_amplitudes),max_reps,peak_to_peak_value)\n",
    "    peak2peak_data_to_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "dd36a46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## make it work with df\n",
    "if create_tensor:\n",
    "    for elec_i in range (len(mt_electrodes['elec_name'])) : #loop through all the elecs\n",
    "        for muscle_i in range (len(mt_muscles['muscle_name'])): # loop through all the muscles\n",
    "            amp_index=0\n",
    "            data_amp_index=0\n",
    "            print(f\" Data search for muscle: {muscle_i} and elec: {elec_i}\")\n",
    "            for amp_in_unique_amp in unique_amplitudes: # loop through all the amplitudes\n",
    "                print(\"#####################################################\")\n",
    "                print(f\"starting data search, for amp: {amp_in_unique_amp} \")\n",
    "                reps=0\n",
    "                # make sure loop doesnt exceed lenght of data, to evade error\n",
    "                if  data_amp_index< len(df_subject[(df_subject[\"Elec_config\"]==elec_i)&(df_subject[\"Muscle\"]== mt_muscles['muscle_name'][muscle_i] )][\"Amplitudes\"]): \n",
    "                    print(\"passed checkpoint\")\n",
    "                    \n",
    "                    #Check for which amplitudes there is data\n",
    "                    data_amp=round(df_subject[(df_subject[\"Elec_config\"]==elec_i)&(df_subject[\"Muscle\"]== mt_muscles['muscle_name'][muscle_i] )].reset_index().iloc[data_amp_index][\"Amplitudes\"], 2)\n",
    "                    print(f\"comparing unique: {amp_in_unique_amp} with data amp: {data_amp}\")\n",
    "                    if data_amp==amp_in_unique_amp:\n",
    "                        print(\"found a suiting amplitude\")\n",
    "                        \n",
    "                        # fill meadian peak to peak value for that amplitude\n",
    "                        print(f\"Only one Rep, thus reps must be zero :{reps} \")\n",
    "                        peak2peak_data_to_tensor[elec_i, muscle_i, amp_index,reps,:]=torch.tensor(df_subject[(df_subject[\"Elec_config\"]==elec_i)&(df_subject[\"Muscle\"]== mt_muscles['muscle_name'][muscle_i])&(round(df_subject[\"Amplitudes\"], 2)== amp_in_unique_amp)][\"Median_Peak2Peak\"].item())\n",
    "                        reps+=1\n",
    "                        peak2peak_data_to_tensor[elec_i, muscle_i, amp_index,reps:,:]=torch.zeros((len(peak2peak_data_to_tensor[elec_i, muscle_i, amp_index,reps:,0]),peak_to_peak_value)).float()\n",
    "                        peak2peak_data_to_tensor[peak2peak_data_to_tensor==0]= float('nan') #didn't find torch.nan function\n",
    "                    \n",
    "                        \n",
    "                            \n",
    "                         \n",
    "                    else:\n",
    "                        print(\"there is no data thus tensor filled with nan\")\n",
    "                        peak2peak_data_to_tensor[elec_i, muscle_i, amp_index,:,:]=torch.zeros(( max_reps,peak_to_peak_value)).float()\n",
    "                        peak2peak_data_to_tensor[peak2peak_data_to_tensor==0]= float('nan') #didn't find torch.nan function\n",
    "                        print(f\"pritning tensor slice for elec: {elec_i}, muscle:{muscle_i} and amp: {amp_in_unique_amp}\")\n",
    "                    \n",
    "                    \n",
    "                # Fill left over data with nan\n",
    "                else:\n",
    "                    #Fill  amplitude the with  nan\n",
    "                    print(f\"no more data for elec: {elec_i}, muscle:{muscle_i}\")\n",
    "                    peak2peak_data_to_tensor[elec_i, muscle_i, amp_index,:,:]=torch.zeros((max_reps,peak_to_peak_value)).float()\n",
    "                    peak2peak_data_to_tensor[peak2peak_data_to_tensor==0]= float('nan') #didn't find torch.nan function\n",
    "                \n",
    "                amp_index+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fb2951",
   "metadata": {},
   "source": [
    "#### Create amplitude tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "22654df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_tensor:\n",
    "    ### Create tensor with size torch.Size([16, 14, 32]) \n",
    "    # nMuslces x nElecs x nAmp_unique \n",
    "    amplitude_filtereddata_to_tensor=torch.ones(len(mt_electrodes['elec_name']),len(mt_muscles['muscle_name']),len(unique_amplitudes))\n",
    "    amplitude_filtereddata_to_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "85cd47c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  working  with df :D\n",
    "if create_tensor:\n",
    "    ## Starting with elec 0, muslce 0, amp=0.5, filling the 10rows (repetition) for the spec. amp with the raw data/ resp nan value since there is no data for that amplitude\n",
    "    for elec_i in range (len(mt_electrodes['elec_name'])) : #loop through all the elecs\n",
    "        for muscle_i in range(len(mt_muscles['muscle_name'])): # loop through all the muscles\n",
    "                \n",
    "            ind=0 # set index to zero, will serve as index from amplitudes\n",
    "            for pos_in_unique_amplitudes in range(len(unique_amplitudes)): #loop through all the amplitudes possible\n",
    "                \n",
    "\n",
    "                if len(df_subject[(df_subject[\"Elec_config\"]==elec_i)&(df_subject[\"Muscle\"]== mt_muscles['muscle_name'][muscle_i] )][\"Amplitudes\"]) > ind: #Make sure not to exceed size of amplitude count\n",
    "                    data_amp=round(df_subject[(df_subject[\"Elec_config\"]==elec_i)&(df_subject[\"Muscle\"]== mt_muscles['muscle_name'][muscle_i] )].reset_index().iloc[ind][\"Amplitudes\"], 2)\n",
    "\n",
    "\n",
    "                    print(f\"Amplitude of unique amp:{unique_amplitudes[pos_in_unique_amplitudes]}, {elec_i}, {mt_muscles['muscle_name'][muscle_i]},  data_amp:{data_amp}\")\n",
    "\n",
    "                    if data_amp > unique_amplitudes[pos_in_unique_amplitudes]:\n",
    "                        print(f\"No data for Amplitude: {unique_amplitudes[pos_in_unique_amplitudes]}, next amp with data: {data_amp} fill  nan for this amplitude\")\n",
    "                        amplitude_filtereddata_to_tensor[elec_i, muscle_i, pos_in_unique_amplitudes]=torch.zeros((1)).float()\n",
    "                        amplitude_filtereddata_to_tensor[amplitude_filtereddata_to_tensor==0]= float('nan') #didn't find torch.nan function\n",
    "                        \n",
    "                    elif data_amp == unique_amplitudes[pos_in_unique_amplitudes]:\n",
    "                        #save the amp with data\n",
    "                        print(\"same amplitude\")\n",
    "                    \n",
    "                        amplitude_filtereddata_to_tensor[elec_i, muscle_i, pos_in_unique_amplitudes]=torch.Tensor([data_amp])\n",
    "                        ind+=1\n",
    "                        print(\"#################################################################\")\n",
    "\n",
    "                \n",
    "                else: #No more data for the remaining amplitudes in unique_amplitudes, thus fill with nan\n",
    "                    print(f\"In combination {elec_i}_{mt_muscles['muscle_name'][muscle_i]} no more data for {unique_amplitudes[pos_in_unique_amplitudes]}, nan value for this and following amplitudes\")\n",
    "                    # amplitude_data_to_tensor[elec_i, muscle_i, pos_in_unique_amplitudes:]=torch.zeros((len(unique_amplitudes)-pos_in_unique_amplitudes)).float()\n",
    "                    amplitude_filtereddata_to_tensor[elec_i, muscle_i, pos_in_unique_amplitudes]=torch.zeros((1)).float()\n",
    "                    amplitude_filtereddata_to_tensor[amplitude_filtereddata_to_tensor==0]= float('nan') #didn't find torch.nan function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6d663a",
   "metadata": {},
   "source": [
    "### Save tensor as pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8b05299c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### save files as pickle file  to projectome_finder#\n",
    "if create_tensor:\n",
    " \n",
    "\n",
    "\n",
    "    file = open(location_data_dump +'robin_data_tensor_dump.pkl', \"wb\")\n",
    "    # file = open('/Users/nealarohner/Desktop/Projectome_Finder/code/Neala_Master_Thesis/data/pickle_files/+'robin_data_tensor_dump.pkl', \"wb\")\n",
    "\n",
    "    obj_1 = filtered_data_to_tensor #torch.Size([16, 16, 40, 39, 1000])\n",
    "    obj_2 = amplitude_filtereddata_to_tensor #torch.Size([16, 16, 40])\n",
    "    obj_3 = peak2peak_data_to_tensor #torch.Size([16, 16, 40, 39, 1])\n",
    "\n",
    "    pickle.dump(obj_1, file)\n",
    "    pickle.dump(obj_2, file)\n",
    "    pickle.dump(obj_3, file)\n",
    "\n",
    "    file.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## to retrieve ##\n",
    "## file = open('/Users/nealarohner/Desktop/Projectome_Finder/code/Neala_Master_Thesis/data/pickle_files/robin_data_tensor_dump.pkl', 'rb')\n",
    "# file = open(location_data_dump+'robin_data_tensor_dump.pkl', 'rb')\n",
    "# filtered_data_to_tensor = pickle.load(file)\n",
    "# amplitude_filtereddata_to_tensor  = pickle.load(file)\n",
    "# peak2peak_data_to_tensor = pickle.load(file)\n",
    "\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77489a3a",
   "metadata": {},
   "source": [
    "## Retrieve pickle and csv data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f4ca046c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if load_data==0:\n",
    "    file = open(location_data_dump +'robin_data_tensor_dump.pkl', 'rb')\n",
    "    filtered_data_to_tensor = pickle.load(file)\n",
    "    amplitude_filtereddata_to_tensor  = pickle.load(file)\n",
    "    peak2peak_data_to_tensor = pickle.load(file)\n",
    "\n",
    "    file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b06e1cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if load_data==0:\n",
    "    # to retrieve ##\n",
    "    mt_electrodes=pd.read_csv(location_data_dump+'mt_electrodes.csv')\n",
    "    mt_muscles=pd.read_csv(location_data_dump+'mt_muscles.csv')\n",
    "    unique_amplitudes=pd.read_csv(location_data_dump + 'unique_amplitudes.csv')\n",
    "\n",
    "    electrodes=list(mt_electrodes[\"elec_name\"])\n",
    "    muscles=list(mt_muscles[\"muscle_name\"])\n",
    "    unique_amplitudes=list(unique_amplitudes[\"amplitudes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8da56366",
   "metadata": {},
   "outputs": [],
   "source": [
    "muscles_left=['LIL','LRF', 'LVL','LST', 'LTA','LMG','LSOL', 'LPS']\n",
    "muscles_right=['RIL','RRF', 'RVL','RST', 'RTA','RMG','RSOL', 'RPS']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0637027d",
   "metadata": {},
   "source": [
    "## Filtered EMG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a566e194",
   "metadata": {},
   "source": [
    "Plot the raw values,thus for every electrode-muscle combination you have a curve for every amplitude for that combination\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "aea65d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_emg_per_electrode(filtered_data_to_tensor=filtered_data_to_tensor,amplitude_filtereddata_to_tensor=amplitude_filtereddata_to_tensor, unique_amplitudes=unique_amplitudes, save_fig=0, mt_electrodes=mt_electrodes):\n",
    "    \"\"\"\n",
    "    A function to create recruitment curves by electrode\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filtered_data_to_tensor\n",
    "        EMG data used for the recruitment curve, set by default\n",
    "    amplitude_filtereddata_to_tensor\n",
    "        Amplitudes used for the recruitment curve, set by default\n",
    "    unique_amplitudes\n",
    "        list with all the amplitudes\n",
    "    save_fig\n",
    "        int, if set to 1 save figure\n",
    "    mt_electrodes\n",
    "        pandas df, all ellectrodes used in data\n",
    "    mt_muscles\n",
    "        pandas df, all muscles used in data\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    for elec_i in range (0, len(mt_electrodes[0:1])):\n",
    "        fig, ax = plt.subplots(figsize=(10,7))\n",
    "        for muscle_i in range (len(mt_muscles[0:1])):\n",
    "            for amplitude_i in range (0, len(amplitude_filtereddata_to_tensor[elec_i, muscle_i, :])):\n",
    "                colors = cm.rainbow(np.linspace(0, 1, len(amplitude_filtereddata_to_tensor[elec_i, muscle_i, :])))\n",
    "                # if no values for that amplitude break for loop\n",
    "                if np.isnan(np.array(amplitude_filtereddata_to_tensor[elec_i, muscle_i, amplitude_i])):\n",
    "                    continue\n",
    "                # Define variables for plotting\n",
    "                x = np.arange(0, len(filtered_data_to_tensor[elec_i, muscle_i, amplitude_i, 0, :]))\n",
    "                y = filtered_data_to_tensor[elec_i, muscle_i, amplitude_i, 0, :]\n",
    "    \n",
    "                # Plot the data points\n",
    "                plt.plot(x,  y, '-', c=colors[amplitude_i], label= unique_amplitudes[amplitude_i]) \n",
    "                \n",
    "            plt.legend(title=\"Amplitude of current [mA]\")\n",
    "            # Set label and scale\n",
    "            ax.set_xlabel(\"Timepoints [in 100 ms]\") # freq. rate = 10kHz, 1000 time points\n",
    "            # ax.set_xticks(ticks=np.linspace(start=0.2, stop=np.max(unique_amplitudes)+0.1, endpoint=True, num=25))\n",
    "            ax.set_ylabel(f\"filtered EMG [mV]\")\n",
    "            # ax.set_xticks(ticks=np.linspace(0, 100))\n",
    "\n",
    "            # Plotting settings\n",
    "            # ax.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "            ax.set_title(f\"Filtered EMG for elec: {elec_i} and muscle: {mt_muscles['muscle_name'][muscle_i]} \")\n",
    "            \n",
    "        ## save plots ##\n",
    "        if save_fig:\n",
    "            folder_name=\"Raw_EMG\"\n",
    "            data_file=\"elec\"+\"_\"+str(elec_i)+\"_\"+\"raw_emg\"+'.png'\n",
    "            save_figure(folder_name, data_file)\n",
    "\n",
    "            plt.show()\n",
    "    \n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "3bed4473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_emg_per_electrode(filtered_data_to_tensor=filtered_data_to_tensor,amplitude_filtereddata_to_tensor=amplitude_filtereddata_to_tensor, unique_amplitudes=unique_amplitudes, save_fig=0, mt_electrodes=mt_electrodes):\n",
    "    \"\"\"\n",
    "    A function to create recruitment curves by electrode\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filtered_data_to_tensor\n",
    "        EMG data used for the recruitment curve, set by default\n",
    "    amplitude_filtereddata_to_tensor\n",
    "        Amplitudes used for the recruitment curve, set by default\n",
    "    unique_amplitudes\n",
    "        np.array with all the amplitudes\n",
    "    save_fig\n",
    "        int, if set to 1 save figure\n",
    "    mt_electrodes\n",
    "        pandas df, all ellectrodes used in data\n",
    "    mt_muscles\n",
    "        pandas df, all muscles used in data\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    for elec_i in range (0, len(mt_electrodes[0:1])):\n",
    "        fig, ax = plt.subplots(figsize=(10,7))\n",
    "        for muscle_i in range (len(mt_muscles[0:1])):\n",
    "            for amplitude_i in range (0, len(amplitude_filtereddata_to_tensor[elec_i, muscle_i, :])):\n",
    "                colors = cm.rainbow(np.linspace(0, 1, len(amplitude_filtereddata_to_tensor[elec_i, muscle_i, :])))\n",
    "                # if no values for that amplitude break for loop\n",
    "                if np.isnan(np.array(amplitude_filtereddata_to_tensor[elec_i, muscle_i, amplitude_i])):\n",
    "                    continue\n",
    "                # Define variables for plotting\n",
    "                x = np.arange(0, len(filtered_data_to_tensor[elec_i, muscle_i, amplitude_i, 0, :]))\n",
    "                y = filtered_data_to_tensor[elec_i, muscle_i, amplitude_i, 0, :]\n",
    "    \n",
    "                # Plot the data points\n",
    "                plt.plot(x,  y, '-', c=colors[amplitude_i], label= unique_amplitudes[amplitude_i]) \n",
    "                \n",
    "            plt.legend(title=\"Amplitude of current [mA]\")\n",
    "            # Set label and scale\n",
    "            ax.set_xlabel(\"Timepoints [in 100 ms]\") # freq. rate = 10kHz, 1000 time points\n",
    "            # ax.set_xticks(ticks=np.linspace(start=0.2, stop=np.max(unique_amplitudes)+0.1, endpoint=True, num=25))\n",
    "            ax.set_ylabel(f\"filtered EMG [mV]\")\n",
    "            # ax.set_xticks(ticks=np.linspace(0, 100))\n",
    "\n",
    "            # Plotting settings\n",
    "            # ax.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "            ax.set_title(f\"Filtered EMG for elec: {elec_i} and muscle: {mt_muscles['muscle_name'][muscle_i]} \")\n",
    "            \n",
    "        ## save plots ##\n",
    "        if save_fig:\n",
    "            folder_name=\"Raw_EMG\"\n",
    "            data_file=\"elec\"+\"_\"+str(elec_i)+\"_\"+\"raw_emg\"+'.png'\n",
    "            save_figure(folder_name, data_file)\n",
    "\n",
    "            plt.show()\n",
    "    \n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ef149749",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_plot:\n",
    "    get_raw_emg_per_electrode(save_fig=save_plot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb78e6a",
   "metadata": {},
   "source": [
    "## EMG Processing -Recruitment curves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb59a85e",
   "metadata": {},
   "source": [
    "For the rectuitment curve per electrode, you have one value ( the peak to peak value) per amplitude for the different muscles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f1036a",
   "metadata": {},
   "source": [
    "### Recruitment per elec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "48b4771a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recruitment_curve_per_electrode(peak2peak_data_to_tensor=peak2peak_data_to_tensor,amplitude_filtereddata_to_tensor=amplitude_filtereddata_to_tensor, unique_amplitudes=unique_amplitudes, save_fig=0, mt_electrodes=mt_electrodes):\n",
    "    \"\"\"\n",
    "    A function to create recruitment curves by electrode\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    peak2peak_data_to_tensor\n",
    "        Peak to peak values of EMG data, used for the recruitment curve, set by default\n",
    "    amplitude_filtereddata_to_tensor\n",
    "        Amplitudes used for the recruitment curve, set by default\n",
    "    unique_amplitudes\n",
    "        np.array with all the amplitudes\n",
    "    save_fig\n",
    "        int, if set to 1 save figure\n",
    "    mt_electrodes\n",
    "        pandas df, all ellectrodes used in data\n",
    "    mt_muscles\n",
    "        pandas df, all muscles used in data\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    colors = cm.rainbow(np.linspace(0, 1, len(mt_muscles)))\n",
    "    label=mt_muscles[\"muscle_name\"]\n",
    "\n",
    "    for elec_i in range (0, len(mt_electrodes)):\n",
    "        fig, ax = plt.subplots(figsize=(10,7))\n",
    "        for muscle_i in range (len(mt_muscles)):\n",
    "\n",
    "            # Define variables for plotting\n",
    "            x = amplitude_filtereddata_to_tensor[elec_i,muscle_i,:]\n",
    "            y = peak2peak_data_to_tensor[elec_i, muscle_i, :, 0, 0]\n",
    "        \n",
    "            # Remove nan values\n",
    "            x_without_nan=np.array(x)\n",
    "            x_without_nan=x_without_nan[~np.isnan(x_without_nan)]\n",
    "            y_without_nan=np.array(y)\n",
    "            y_without_nan=y_without_nan[~np.isnan(y_without_nan)]\n",
    "\n",
    "            # Plot the data points\n",
    "            plt.plot(x_without_nan,  y_without_nan, 'o-', c=colors[muscle_i], label= mt_muscles['muscle_name'][muscle_i]) \n",
    "            \n",
    "            # Add text descripiton to the points for visibility\n",
    "            for index in range (len(x_without_nan)):\n",
    "                ax.text(x_without_nan[index], y_without_nan[index], label[muscle_i], size=10) \n",
    "            \n",
    "            # Set label and scale\n",
    "            ax.set_xlabel(\"Amplitude [mA]\")\n",
    "            ax.set_xticks(ticks=np.linspace(start=0.2, stop=np.max(unique_amplitudes)+0.1, endpoint=True, num=25))\n",
    "            ax.set_ylabel(f\"Peak to peak value [mV]\")\n",
    "            ax.set_yticks(ticks=np.linspace(0, np.nanmax(peak2peak_data_to_tensor [:, :,:, 0, 0]), 11))\n",
    "\n",
    "        # Plotting settings\n",
    "        ax.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left', title=\"muscles\")\n",
    "        ax.set_title(f\"Recruitment curve for elec: {elec_i}\")\n",
    "\n",
    "        ## save plots ##\n",
    "        if save_fig:\n",
    "            data_file = \"elec\"+\"_\"+str(elec_i)+\"_\"+\"recruitment_curve\"+'.png'\n",
    "            folder_name=\"recruitment_curve/muscles/recruitment_per_elec\"\n",
    "            save_figure(folder_name, data_file)\n",
    "\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e3a53a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_plot:\n",
    "    get_recruitment_curve_per_electrode(save_fig=save_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e2737b",
   "metadata": {},
   "source": [
    "### Recruitment per muscle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a67c22c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_recruitment_curve_per_muscles(peak2peak_data_to_tensor=peak2peak_data_to_tensor,amplitude_filtereddata_to_tensor=amplitude_filtereddata_to_tensor,unique_amplitudes=unique_amplitudes,  save_fig=0, mt_electrodes=mt_electrodes):\n",
    "    \"\"\"\n",
    "    A function to create recruitment curves by muscle. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    peak2peak_data_to_tensor\n",
    "        EMG data used for the recruitment curve, set by default\n",
    "    amplitude_filtereddata_to_tensor\n",
    "        Amplitudes used for the recruitment curve, set by default\n",
    "    unique_amplitudes\n",
    "        np.array with all the amplitudes\n",
    "    save_fig\n",
    "        int, if set to 1 save figure\n",
    "    mt_electrodes\n",
    "        pandas df, all ellectrodes used in data\n",
    "    mt_muscles\n",
    "        pandas df, all muscles used in data\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    colors = cm.rainbow(np.linspace(0, 1, len(mt_electrodes)))\n",
    "    label=mt_electrodes[\"elec_name\"]\n",
    "\n",
    "    for muscle_i in range (len(mt_muscles)):\n",
    "        fig, ax = plt.subplots(figsize=(10,7))\n",
    "        for elec_i in range (0, len(mt_electrodes)):\n",
    "        \n",
    "            # Define variables for plotting\n",
    "            x = amplitude_filtereddata_to_tensor[elec_i,muscle_i,:]\n",
    "            y = peak2peak_data_to_tensor[elec_i, muscle_i, :, 0, 0]\n",
    "        \n",
    "            # Remove nan values for the text index\n",
    "            x_without_nan=np.array(x)\n",
    "            x_without_nan=x_without_nan[~np.isnan(x_without_nan)]\n",
    "            y_without_nan=np.array(y)\n",
    "            y_without_nan=y_without_nan[~np.isnan(y_without_nan)]\n",
    "\n",
    "            # Plot the data points\n",
    "            plt.plot(x_without_nan, y_without_nan, 'o-', c=colors[elec_i],  label=mt_electrodes['elec_name'][elec_i]) \n",
    "                \n",
    "            # Add text descripiton to the points for visibility\n",
    "            for index in range (len(x_without_nan)):\n",
    "                ax.text(x_without_nan[index], y_without_nan[index], label[elec_i], size=10) \n",
    "            \n",
    "            # Set label and scale\n",
    "            ax.set_xlabel(\"Amplitude [mA]\")\n",
    "            ax.set_xticks(ticks=np.linspace(start=0.2, stop=np.max(unique_amplitudes)+0.1, endpoint=True, num=25))\n",
    "            ax.set_ylabel(f\"Peak to peak value [mV]\")\n",
    "            ax.set_yticks(ticks=np.linspace(0, np.nanmax(peak2peak_data_to_tensor [:, :,:, 0, 0]), 11))\n",
    "\n",
    "        # Plotting settings\n",
    "        ax.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left', title= \"electrodes\")\n",
    "        ax.set_title(f\"Recruitment curve for muscle {mt_muscles['muscle_name'][muscle_i]}\")\n",
    "\n",
    "        ## save plots ##\n",
    "        if save_fig:\n",
    "            data_file = mt_muscles['muscle_name'][muscle_i]+\"_\"+\"recruitment_curve\"+'.png'\n",
    "            folder_name=\"recruitment_curve/muscles/recruitment_per_msc\"\n",
    "            save_figure(folder_name, data_file)\n",
    "\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e84f6e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_plot:\n",
    "    get_recruitment_curve_per_muscles(save_fig=save_plot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632c89b0",
   "metadata": {},
   "source": [
    "## Muscle recruitment processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550982c4",
   "metadata": {},
   "source": [
    "For now there are two possibibilites \n",
    "\n",
    "**A: Heatmap**\n",
    "\n",
    "Since there is an inconsistent sweep of amplitudes between the electrodes (some elctrodes are not stimulating as high as others) it's hard to compare the activation of the muscle between the electrodes and define the electrode(s) that predominantly activate a certain muscle.\n",
    "Thus here we have different approaches to solve this problem:\n",
    "\n",
    "Normalisation methods:\n",
    "- Normalise by amplitude:\n",
    "    - for peak to peak values: max output(max activation) / input(amp) at max activation\n",
    "    - for integral (hasn't been done yet): output int /input (amp) bim max \n",
    "- Normalise by max value\n",
    "- Selectivity index (described in paper)(not done yet) (not recommended)\n",
    "\n",
    "\n",
    "**B: Fit recruitment to sigmoids**\n",
    "\n",
    "Here the insconsistent sweep is less of an issue, since we are eitherway interpolating the values with our fit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8786c195",
   "metadata": {},
   "source": [
    "### A: Heat map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d9e052",
   "metadata": {},
   "source": [
    "#### Normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3df5bc",
   "metadata": {},
   "source": [
    "\n",
    "##### normalise_max_P2P_div_amp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204a144b",
   "metadata": {},
   "source": [
    "For every muscle electrode combination the max muscle response is divided by the ampliude at that point. \n",
    "However with this method we don't take into account the impedance. There's a big variability between the different electrodes (eg  impedance given by tissue btw elec and return.  eg air bubble etc )\n",
    "After having done the normalisation by amplitude, there is a problem with the low values for the interpolation: values between 0 and 1 will be rounded to zero. Thus we have to multiply it by 100 before interpolating\n",
    "and change the plotting scale (vmin, and vmax) to 0 to 100, thus we should get to the same results and in the heatmap without interpolation where data_1 was used, and vmin=0 and vmax=1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "a370466c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_normalisation_max_p2p_div_amp(mt_muscles=mt_muscles,mt_electrodes=mt_electrodes):\n",
    "    \"\"\"\"\n",
    "    Function to get a number for the heat map\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mt_muscles\n",
    "        df of all the muscles in the gait, set by default\n",
    "    mt_electrodes\n",
    "        df of all the electrodes used, set by default\n",
    "\n",
    "    Output\n",
    "    ----------\n",
    "    data_normalised\n",
    "        numpy array of values \"normalised\"\n",
    "    \"\"\"\n",
    "\n",
    "    data_normalised=np.zeros((len(mt_muscles[\"muscle_name\"]),len(mt_electrodes[\"elec_name\"])))\n",
    "    for muscle_i in range(0, len(mt_muscles)):\n",
    "        for elec_i in range (0, len(mt_electrodes)):\n",
    "            ## Find max value for one combination\n",
    "            max_value=np.nanmax(peak2peak_data_to_tensor[elec_i, muscle_i, :, 0, 0])\n",
    "            ## Divide max value by amplitude at max value to normalise (not just between muscles but also between elecs)\n",
    "            max_value_amplitude=amplitude_filtereddata_to_tensor[elec_i,muscle_i,np.where(max_value==peak2peak_data_to_tensor[elec_i, muscle_i, :, 0, 0])[0][0]]\n",
    "        \n",
    "            max_value_normalised=np.divide(max_value,max_value_amplitude)\n",
    "            data_normalised[muscle_i][elec_i]=max_value_normalised\n",
    "    \n",
    "    ## turn into a df\n",
    "    data_normalised_df= pd.DataFrame(data_normalised, columns=mt_electrodes[\"elec_name\"], index=mt_muscles[\"muscle_name\"])\n",
    "\n",
    "    print(\"normalisation method is: normalise_max_P2P_div_amp\")\n",
    "    return data_normalised_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc540767",
   "metadata": {},
   "source": [
    "\n",
    "##### normalise_by_max_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c527ff85",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Idea of Robin : across all elecs,  take max response in the muscle (peak to peak ?, at any amp?)\n",
    "and normalise by that. Here we take into account the impendance difference between the different electrodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "08165b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as df\n",
    "def set_normalisation_by_max_response(mt_muscles=mt_muscles,mt_electrodes=mt_electrodes):\n",
    "    \"\"\"\"\n",
    "    Function to get a number for the heat map\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mt_muscles\n",
    "        df of all the muscles in the gait, set by default\n",
    "    mt_electrodes\n",
    "        df of all the electrodes used, set by default\n",
    "\n",
    "    Output\n",
    "    ----------\n",
    "    data_normalised_df\n",
    "        numpy array of values \"normalised\"\n",
    "    \"\"\"\n",
    "\n",
    "    data_normalised=np.zeros((len(mt_muscles[\"muscle_name\"]),len(mt_electrodes[\"elec_name\"])))\n",
    "    for muscle_i in range(0, len(mt_muscles)):\n",
    "        for elec_i in range (0, len(mt_electrodes)):\n",
    "            ## Find max response in the muscle\n",
    "            max_value_for_muscle=np.nanmax(peak2peak_data_to_tensor[:, muscle_i, :, 0, 0])\n",
    "            max_value_normalised=np.divide(np.nanmax(peak2peak_data_to_tensor[elec_i, muscle_i, :, 0, 0]), max_value_for_muscle)\n",
    "        \n",
    "            data_normalised[muscle_i][elec_i]= max_value_normalised\n",
    "\n",
    "    ## turn into a df\n",
    "    data_normalised_df= pd.DataFrame(data_normalised, columns=mt_electrodes[\"elec_name\"], index=mt_muscles[\"muscle_name\"])\n",
    "\n",
    "    print(\"normalisation method is: normalise_max_response to df\")\n",
    "    print(\" Data is in a df structure\")\n",
    "    return data_normalised_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478c1f17",
   "metadata": {},
   "source": [
    "#### Heat map all muscles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "624b2a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_heatmap_all_muscles_overview(save_fig=0, mt_muscles=mt_muscles,mt_electrodes=mt_electrodes):\n",
    "    \"\"\"\n",
    "    A function to create a heatmap.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    save_fig\n",
    "        int, if set to 1 save figure\n",
    "    mt_muscles\n",
    "        df of all the muscles in the gait, set by default\n",
    "    mt_electrodes\n",
    "        df of all the electrodes used, set by default\n",
    "    \"\"\"\n",
    "            \n",
    "    fig, ax = plt.subplots(figsize=(15,10))# creating subplot\n",
    "\n",
    "    ## Define which normalisation method is used\n",
    "    # data=set_normalisation_max_p2p_div_amp(mt_muscles=mt_muscles,mt_electrodes=mt_electrodes)\n",
    "    # data_structure=\"normalise_max_P2P_div_amp\"\n",
    "    data=set_normalisation_by_max_response(mt_muscles=mt_muscles,mt_electrodes=mt_electrodes)\n",
    "    data_structure=\"normalise_by_max_response\"\n",
    "    \n",
    "    ## Define heatmap\n",
    "    sns.heatmap(data=data, cmap=\"Reds\", cbar=True,\n",
    "    annot=True,  yticklabels=mt_muscles[\"muscle_name\"],\n",
    "    xticklabels=mt_electrodes[\"elec_name\"],\n",
    "    cbar_kws={'label': f\"Muscle activation ['V/A']\"},\n",
    "    fmt='.2g' )\n",
    " \n",
    "    ## Define ticks\n",
    "    plt.tick_params(axis='both', which='major', labelsize=10, labelbottom = False, bottom=False, top = False, labeltop=True)\n",
    "\n",
    "    ## Define labels\n",
    "    ax.set_title('Heat map for muscle activation per electrode', size=18, fontstyle='italic', pad=20)\n",
    "    ax.set_ylabel('Muscles',  size=12, fontstyle='italic', labelpad=10, color=\"grey\", fontweight=\"bold\") \n",
    "    ax.xaxis.set_label_position('top') \n",
    "    ax.set_xlabel('Electrodes', size=12, fontstyle='italic', labelpad=10, color=\"grey\", fontweight=\"bold\")\n",
    "\n",
    "    \n",
    "    ## Define Textbox\n",
    "    print(f\"Heat map is being created with Normalisation method: {data_structure}\")\n",
    "    axbox = fig.add_axes([0, 1.0, 0.2, 0.05]) #[left, bottom, width, height]\n",
    "    text_box = TextBox(axbox,label=None, textalignment=\"center\")\n",
    "    text_box.set_val(data_structure)  # Trigger `submit` with the initial string.\n",
    "\n",
    "    ## Save plots   \n",
    "    if save_fig:\n",
    "        folder_name= \"heatmap/muscles\"\n",
    "        data_file = \"Heat_map_all_muscles_\"+ data_structure+'.png'\n",
    "        save_figure(folder_name, data_file)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b20ffc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_plot:\n",
    "    get_heatmap_all_muscles_overview(save_fig=save_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bc6d17",
   "metadata": {},
   "source": [
    "#### Heat map indiviudal muscles, paddle lead arrangement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3541ad",
   "metadata": {},
   "source": [
    "\n",
    "Which interpolatio approach should be used??\n",
    "https://support.esri.com/en/technical-article/000005606\n",
    "Since we have a continuous data: \n",
    "     where the location of the electrode  is the  hotspot (=point of highest stimulation), and the area around is stimulated aswell but at a certain decay of the hotspot\n",
    "\n",
    "- linear interpolation is suited for continuos data and takes into account the 4 neighbouring cells\n",
    "- cubic interpolation lead to smoother curves of the data (resp. colour changes) since it takes into account the 16 surrounding cells of a an output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "4f2983e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Interpolate unknown values in the heat map ###\n",
    "\n",
    "def interpolate_missing_pixels(image, mask, method, fill_value=0):\n",
    "\n",
    "    \"\"\"\n",
    "    A function to interpolate missing values.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image \n",
    "        2D np.array\n",
    "    mask\n",
    "        a 2D boolean array, True indicates missing values\n",
    "    method\n",
    "        interpolation method, one of 'nearest', 'linear', 'cubic'.\n",
    "    fill_value\n",
    "        which value to use for filling up data outside the\n",
    "        convex hull of known pixel values.\n",
    "        Default is 0, Has no effect for 'nearest'.\n",
    "        \n",
    "    Return\n",
    "    ----------\n",
    "    interp_image\n",
    "        nd.array with missing values interpolated\n",
    "    \"\"\"\n",
    "\n",
    "    h, w = image.shape[:2]\n",
    "    xx, yy = np.meshgrid(np.arange(w), np.arange(h))\n",
    "\n",
    "    known_x = xx[~mask]\n",
    "    known_y = yy[~mask]\n",
    "    known_v = image[~mask]\n",
    "    missing_x = xx[mask]\n",
    "    missing_y = yy[mask]\n",
    "\n",
    "    interp_values = interpolate.griddata(\n",
    "        (known_x, known_y), known_v, (missing_x, missing_y),\n",
    "        method=method, fill_value=fill_value\n",
    "    )\n",
    "\n",
    "    interp_image = image.copy()\n",
    "    interp_image[missing_y, missing_x] = interp_values\n",
    "\n",
    "    return interp_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c2eb398d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### text to define electrodes in plot\n",
    "text = np.array([\n",
    "['', '','', '','', '', '', '', ''], ['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],\n",
    "['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],\n",
    "['', '','', '','1', '', '', '', ''],['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],\n",
    "['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],\n",
    "['', '','', '','', '', '', '', ''],['', '7','', '','', '', '', '13', ''],['', '','', '','', '', '', '', ''],\n",
    "['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],\n",
    "['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],\n",
    "['', '','', '','0', '', '', '', ''],['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],\n",
    "['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],\n",
    "['', '','', '','', '', '', '', ''],['', '6','', '','', '', '', '12', ''],['', '','', '','', '', '', '', ''],\n",
    "['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],\n",
    "['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],['', '','', '','15', '', '', '', ''],\n",
    "['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],\n",
    "['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],\n",
    "['', '','', '','', '', '', '', ''], ['', '5','', '','', '', '', '11', ''],['', '','', '','', '', '', '', ''],\n",
    "['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],\n",
    "['', '','', '','', '', '', '', ''],['', '','', '','14', '', '', '', ''],['', '','', '','', '', '', '', ''],\n",
    "['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],\n",
    "['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],['', '4','', '','', '', '', '10', ''],\n",
    "['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],\n",
    "['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],\n",
    "['', '','', '','', '', '', '', ''], ['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],\n",
    "['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],\n",
    "['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],['', '3','', '2','', '8', '', '9', ''],\n",
    "['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],\n",
    "['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],\n",
    "['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],\n",
    "['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', '']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "1ede1211",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combine interpolated and non-interpolated heatmap\n",
    "def get_heat_map_individual_msc_recruitment(interpolation=0, save_fig=0, interpol_method='cubic', text=text, mt_muscles=mt_muscles, mt_electrodes=mt_electrodes):\n",
    "    \"\"\"\n",
    "    A function to create a heatmap.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    interpolation\n",
    "        int, if set to one, generates heat maps with interpolation, 0 by default\n",
    "    save_fig\n",
    "        int, if set to 1 save figure, 0 by default\n",
    "    interpol_method\n",
    "        interpolation method, one of 'nearest', 'linear', 'cubic'\n",
    "    text\n",
    "        array used for annotation; to define electrodes in the plot\n",
    "    mt_muscles\n",
    "        df of all the muscles in the gait, set by default\n",
    "    mt_electrodes\n",
    "        df of all the electrodes used, set by default\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    ## Define which normalisation method is used ##\n",
    "    # data=set_normalisation_max_p2p_div_amp(mt_muscles=mt_muscles,mt_electrodes=mt_electrodes)\n",
    "    # data_structure=\"normalise_max_P2P_div_amp\"\n",
    "    data=set_normalisation_by_max_response(mt_muscles=mt_muscles,mt_electrodes=mt_electrodes)\n",
    "    data_structure=\"normalise_by_max_response\"\n",
    "\n",
    "\n",
    "    ## Define paddle lead\n",
    "    if interpolation:\n",
    "        print(\"Heat map s being interpolated\")\n",
    "        # Since it would round values between 0 and 1 to 0, we multiply data by 100\n",
    "        data=data *100\n",
    "        # Build tensor filled with -1, thus undefined values are easily recognisable ##    \n",
    "        paddle_lead =np.zeros(80* 9)\n",
    "        paddle_lead=np.array([-1]*len(paddle_lead))\n",
    "        paddle_lead=paddle_lead.reshape((80,9))\n",
    "        method=\"interpolated\"\n",
    "\n",
    "    else:\n",
    "        print(\"No interpoaltion is used for the heat map\")\n",
    "        method=\"non_interpolated\"\n",
    "        paddle_lead =np.zeros(80* 9)\n",
    "        paddle_lead=paddle_lead.reshape((80,9))\n",
    "\n",
    "    ## Get the lead image as an array so we can plot it ##\n",
    "    map_img = mpimg.imread('/Users/nealarohner/Desktop/Projectome_Finder/code/Refrences/lead_original.png') \n",
    "    \n",
    "    ## For every muscle fill paddle lead with values ##\n",
    "    for muscle_i in range(len(mt_muscles)):\n",
    "        \n",
    "        # Set settings for plot ## \n",
    "        fig, ax = plt.subplots(figsize=(3,10))# creating subplot\n",
    "        # Set title\n",
    "        ax.set_title(f\"{method} heat map for muscle {mt_muscles['muscle_name'][muscle_i]}\", size=18, fontstyle='italic', pad=20)\n",
    "    \n",
    "        # Define electrode placements\n",
    "        numbers=[1, 0, 15, 14]\n",
    "        for index, number in enumerate(numbers, start=0): \n",
    "            n=(14*index)+3 # equal spacing\n",
    "            row=4\n",
    "            e=number\n",
    "            #save the same value for all the pixels in the electrode\n",
    "            for i in range(6):\n",
    "                    paddle_lead[i+n][row] =data.loc[mt_muscles[\"muscle_name\"][muscle_i], e]\n",
    "                    # print(i+n)\n",
    "\n",
    "        numbers=[7, 6, 5, 4]\n",
    "        for index, number in enumerate(numbers, start=0):  \n",
    "            n=(14*index)+10 # equal spacing\n",
    "            row=1\n",
    "            e=number\n",
    "            #save the same value for all the pixels in the electrode\n",
    "            for i in range(6):\n",
    "            \n",
    "                    paddle_lead[i+n][row] =data.loc[mt_muscles[\"muscle_name\"][muscle_i], e]\n",
    "\n",
    "        numbers=[13, 12, 11, 10]\n",
    "        for index, number in enumerate(numbers, start=0):   \n",
    "            n=(14*index)+10 # equal spacing\n",
    "            row=7\n",
    "            e=number\n",
    "            #save the same value for all the pixels in the electrode\n",
    "            for i in range(6):\n",
    "                    paddle_lead[i+n][row] =data.loc[mt_muscles[\"muscle_name\"][muscle_i], e]\n",
    "\n",
    "        numbers=[3, 2, 8, 9]\n",
    "        for index, number in enumerate(numbers, start=0):  \n",
    "            n=55+10\n",
    "            row=1+(index*2)\n",
    "            e=number\n",
    "            #save the same value for all the pixels in the electrode\n",
    "            for i in range(6):\n",
    "                    paddle_lead[i+n][row] =data.loc[mt_muscles[\"muscle_name\"][muscle_i], e]\n",
    "        \n",
    "        if interpolation:\n",
    "            # interpolate unknown values\n",
    "            # Create boolean, with true for the unknown values, which were set to -1, for interpolation #\n",
    "            mask=paddle_lead<0\n",
    "\n",
    "            ## Get interpolation for the unknown values ##\n",
    "            interpolated_image=interpolate_missing_pixels(\n",
    "            image=paddle_lead,\n",
    "            mask=mask,\n",
    "            method=interpol_method,\n",
    "            fill_value= 0\n",
    "            )\n",
    "\n",
    "            ## Set values outside of lead to zero ##\n",
    "            # do it after interpolation that this doent get taken into account for interpol\n",
    "            nr_columns=[8, 4, 2, 1, 1, 1, 2, 4, 8]\n",
    "            for index, columns in enumerate(nr_columns):\n",
    "                for col in range(0, columns):\n",
    "                        interpolated_image[col][0+index] =0\n",
    "\n",
    "            nr_columns=[7, 5,4, 4, 4, 4,4, 5, 7]\n",
    "            for index, columns in enumerate(nr_columns):\n",
    "                for col in range(79, 79-columns, -1):\n",
    "                        interpolated_image[col][0+index] =0\n",
    "\n",
    "            \n",
    "        ## Drawing heatmap on current axes ##\n",
    "        if interpolation:\n",
    "            hmax= sns.heatmap(\n",
    "                data=interpolated_image, annot=text, fmt=\"\",\n",
    "                cmap=LinearSegmentedColormap.from_list('', ['white', 'r']),\n",
    "                cbar_kws={'label': \"Muscle activation [V/A]\"},\n",
    "                yticklabels=False, xticklabels=False, vmin=0, \n",
    "                #vmax=100, \n",
    "                alpha = 0.75, # whole heatmap is translucent\n",
    "                zorder = 2,\n",
    "                    )\n",
    "        else:\n",
    "            hmax= sns.heatmap(\n",
    "            data=paddle_lead, annot=text, fmt=\"\",\n",
    "            cmap=LinearSegmentedColormap.from_list('', ['white', 'r']),\n",
    "            cbar_kws={'label': \"Muscle activation [V/A]\"},\n",
    "            yticklabels=False, xticklabels=False, vmin=0, \n",
    "            #vmax=100, \n",
    "            alpha = 0.75, # whole heatmap is translucent\n",
    "            zorder = 2,\n",
    "                )\n",
    "        \n",
    "        ## put the image under the heatmap\n",
    "        hmax.imshow(map_img,\n",
    "            aspect = hmax.get_aspect(),\n",
    "            extent =hmax.get_xlim() + hmax.get_ylim(),\n",
    "            zorder = 1) \n",
    "        \n",
    "        ## Define Textbox\n",
    "        axbox = fig.add_axes([-0.5, 1.0, 1., 0.05]) #[left, bottom, width, height]\n",
    "        text_box = TextBox(axbox,label=None, textalignment=\"center\")\n",
    "        text_box.set_val(data_structure)  # Trigger `submit` with the initial string.\n",
    "\n",
    "        ## Save plots \n",
    "        if save_fig:\n",
    "            folder_name= f\"heatmap/muscles/{method}/{data_structure}\"\n",
    "            data_file = mt_muscles['muscle_name'][muscle_i]+\"_\"+\"heat_map\"+'.png'\n",
    "            save_figure(folder_name, data_file)\n",
    "        show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "bafbf2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_plot:\n",
    "    get_heat_map_individual_msc_recruitment(interpolation=1, save_fig=save_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d93160",
   "metadata": {},
   "source": [
    "### B: Fit recruitment to sigmoids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945ead8b",
   "metadata": {},
   "source": [
    "A possible plan could then be to take a look at the parameters of sigmoid after the fit (and the goodness of the fit) and use go from those to describe the data.\n",
    "Then comparing these to the ones obtained with the simulations.\n",
    "\n",
    "- function to get for a combination the popt\n",
    "- plot all the muscle fits for an electrode\n",
    "\n",
    "- evt. get a version where max value is higher than data point \n",
    "    - compute it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "8c314074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x, L ,x0, k, b):\n",
    "    \"\"\"\n",
    "    A function to define a sigmoid curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    L \n",
    "        is the limes\n",
    "    x0 \n",
    "        is the point in the middle of the Sigmoid, i.e. the point where Sigmoid should originally output the value 1/2 \n",
    "    k \n",
    "        the slope; is responsible for scaling the input, which remains in (-inf,inf)\n",
    "    b \n",
    "        adds bias \n",
    "     \"\"\"\n",
    "\n",
    "\n",
    "    y = L / (1 + np.exp(-k*(x-x0))) + b\n",
    "    return (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "c507436e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_df_combined(xdata, ydata, x_fit, y_fit, msc_o_rt_i,roots=roots):\n",
    "        \"\"\"\n",
    "        Function to get xdata,ydata and combine it with fitted data to a df\n",
    "        \"\"\"\n",
    "\n",
    "        data_you_need=pd.DataFrame()\n",
    "\n",
    "        ## combine data to a table to be able to make a nice legend\n",
    "        ## combine datapoints, and fitted points\n",
    "        \n",
    "        data_points = {'x': xdata,\n",
    "                'y': ydata,\n",
    "                'type': np.array([\"data\"]*len(xdata)), \n",
    "                'name': np.array([roots[msc_o_rt_i]]*len(xdata))\n",
    "                }\n",
    "\n",
    "        data_points = pd.DataFrame(data_points)\n",
    "        fit = {'x': x_fit,\n",
    "                'y': y_fit,\n",
    "                'type': np.array([\"fit from data\"]*len(x_fit)), \n",
    "                'name': np.array([roots[msc_o_rt_i]]*len(x_fit))\n",
    "                }\n",
    "        fit = pd.DataFrame(fit)\n",
    "        combined=pd.concat([data_points, fit])\n",
    "        data_you_need=pd.concat([data_you_need, combined])\n",
    "\n",
    "        return data_you_need\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "a64e654a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_sigmoid(msc_o_rt_i,elec_i, combined,xdata, ydata, x_fit, y_fit, structure_class,save_fig=save_plot, muscles=muscles, roots=roots):\n",
    "    \"\"\"\n",
    "    A function to fit a sigmoid curve to given data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    \"\"\"\n",
    "    # adapt savefig\n",
    "    ## Define variables for plot\n",
    "    colors ='#FA525B'\n",
    "    ## creating subplot\n",
    "    fig, ax = plt.subplots(figsize=(10,7))\n",
    "    \n",
    "\n",
    "    if structure_class==\"roots\":\n",
    "        label=roots\n",
    "        \n",
    "        # solve  ValueError: cannot reindex from a duplicate axis.\n",
    "        combined = combined.reset_index(drop=True)\n",
    "        sns.lineplot(data=combined, x=\"x\", y=\"y\", hue=\"name\", style=\"type\")\n",
    "        ## set titles\n",
    "        ax.set_xlabel(\"Electric current [a.u]\")\n",
    "        ax.set_ylabel(\"Recruitment [?]\")\n",
    "        # plt.legend(title=\"roots\")\n",
    "        plt.title(f\"Fitting data to sigmoid for electrode: {elec_i} \")\n",
    "    \n",
    "\n",
    "\n",
    "    if structure_class==\"muscles\":\n",
    "        label=muscles\n",
    "        ax.plot(xdata, ydata, 'o', c=colors)\n",
    "        ax.plot(x_fit,y_fit,  label=label[msc_o_rt_i], c=colors)\n",
    "\n",
    "        # Add text descripiton to the points for visibility\n",
    "        ax.text(x_fit[-1], y_fit[-1], label[msc_o_rt_i],c=colors, size=10) \n",
    "        ## set ticks\n",
    "        ax.set_xticks(ticks=np.arange(0, 55,5), labels=np.linspace(0, 5,11)) # since amplitudes are multiplied by 10, customise the xlable\n",
    "        ax.set_yticks(ticks=np.linspace(0, 1.,11))\n",
    "\n",
    "        ## set titles\n",
    "        ax.set_xlabel(\"Amplitude [10^-4 A]\")\n",
    "        ax.set_ylabel(\"Peak to peak value [mV]\")\n",
    "        plt.legend(title=\"muscles\")\n",
    "        plt.title(f\"Fitting data to sigmoid for electrode: {elec_i} \")\n",
    "    \n",
    "\n",
    "    \n",
    "        \n",
    "\n",
    "    if save_fig:\n",
    "        data_file = structure_class+\"_elec_\"+str(elec_i)+\"_\"+str(msc_o_rt_i)+\"_sigmoid_fit_\"+subject+\".png\"\n",
    "        folder_name=f\"sigmoidal_fit/{structure_class}/individual\"\n",
    "        save_figure(folder_name, data_file)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "74d2de33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit_sigmoid_max_value_given(data,plot,elec_i,muscle_i, structure_class))\n",
    "def fit_sigmoid_max_value_given(plot,elec_i,msc_o_rt_i,structure_class, save_fig=plot, unique_amplitudes=unique_amplitudes, peak2peak_data_to_tensor=peak2peak_data_to_tensor, roots_recruitment_to_tensor=roots_recruitment_to_tensor):\n",
    "    \"\"\"\n",
    "    A function to fit a sigmoid curve to given data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    plot\n",
    "\n",
    "    elec_i\n",
    "        int, nr of electrode\n",
    "    msc_o_rt_i\n",
    "        int, nr of muscle or root\n",
    "    msc_o_rt_one_side\n",
    "        list, left or right\n",
    "    save_fig\n",
    "        int, if set to 1 save figure, default set to 0 \n",
    "    data\n",
    "        ..\n",
    "    \n",
    "    Output\n",
    "    ----------\n",
    "    popt \n",
    "        is the optimal parameters for the function\n",
    "    \"\"\"\n",
    "    print(msc_o_rt_i )\n",
    "    if structure_class==\"muscles\":\n",
    "        data=peak2peak_data_to_tensor\n",
    "\n",
    "        ## Get rid of nan values\n",
    "        data=np.array(data[elec_i,msc_o_rt_i, :,0,0]) # turn tensor into array\n",
    "        mask = ~np.isnan(data) # search for posistions of nan values\n",
    "        ydata=data[mask] # set y without nan values\n",
    "        \n",
    "        #multiply amplitdes by 10 , seems like it can interpret the values better\n",
    "        xdata = np.array(unique_amplitudes)[mask]# set x for y\n",
    "        xdata = xdata*10\n",
    "    \n",
    "    if structure_class==\"roots\":\n",
    "        data=roots_recruitment_to_tensor\n",
    "        ## set known values\n",
    "        print(\"Is it possible\")\n",
    "        print(roots[ msc_o_rt_i])\n",
    "        print(msc_o_rt_i)\n",
    "        ydata=np.array(data[elec_i,msc_o_rt_i, :]) # turn tensor into array\n",
    "        xdata = np.arange(0, 100)# set x for y\n",
    "    \n",
    "    ## get fitted values for the data points \n",
    "    ## Initial guess for the parameters ##\n",
    "    p0 =[max(ydata) ,np.median(xdata), 0.5, min(ydata)]\n",
    "\n",
    "    ## to avoid RuntimeError: Optimal parameters not found: The maximum number of function evaluations is exceeded.\n",
    "    ##smoothen data if needed\n",
    "    try:\n",
    "        popt, pcov = curve_fit(sigmoid, xdata, ydata,p0, method='dogbox',\n",
    "        # bounds=(0,L)\n",
    "        maxfev=10000\n",
    "        )\n",
    "\n",
    "    except:\n",
    "        print(\"############################################################\")\n",
    "        print(\" Avoid RuntimeError\")\n",
    "        ## smoothen the data by convoluting it with a rectangle \n",
    "        # seems to look smoother, but is this feasible with so few data points?\n",
    "        filt= np.ones(3)/3 # setting window to three points\n",
    "        ydata_smooth= np.convolve(ydata, filt, mode=\"valid\")\n",
    "        ydata=ydata_smooth\n",
    "        xdata=xdata[1:-1] # change borders, since we need space for the window\n",
    "        popt, pcov = curve_fit(sigmoid, xdata, ydata,p0, method='dogbox',\n",
    "        # bounds=(0,L)\n",
    "        maxfev=10000\n",
    "        )\n",
    "\n",
    "\n",
    "    ###################\n",
    "    ## PLOT SETTINGS ##\n",
    "    ###################\n",
    "    \n",
    "    if plot:\n",
    "\n",
    "        ## define x and y for sigmoidal curve\n",
    "        #interpolation should start before data and end a little after ( to see asymptote)\n",
    "        if structure_class==\"muscles\":\n",
    "            print(f\"plotting for {structure_class}\")\n",
    "            ## define x and y for sigmoidal curve\n",
    "            #interpolation should start before data and end a little after ( to see asymptote)\n",
    "            if max(xdata)>44:\n",
    "                last_x_value=49\n",
    "            else:\n",
    "                last_x_value=max(xdata)+5\n",
    "            x_fit=np.linspace(0, last_x_value, 70) #take a lot of steps for smoother curve, and doens't seem to have effect on pcov\n",
    "            y_fit = sigmoid(x_fit, *popt)\n",
    "            plot_sigmoid(msc_o_rt_i, elec_i,combined=0,xdata=xdata, ydata=ydata, x_fit=x_fit, y_fit=y_fit,structure_class=structure_class)\n",
    "        elif structure_class==\"roots\":\n",
    "            print(f\"plotting for {structure_class}\")\n",
    "            x_fit=np.linspace(0, xdata[-3], len(xdata-3)) #take a lot of steps for smoother curve, and doens't seem to have effect on pcov\n",
    "            y_fit = sigmoid(x_fit, *popt)\n",
    "            ## get x and y values with fitted values combined in one df\n",
    "            combined=get_df_combined(xdata, ydata, x_fit, y_fit, msc_o_rt_i)\n",
    "            plot_sigmoid(msc_o_rt_i,elec_i, combined,xdata=0, ydata=0, x_fit=0, y_fit=0, structure_class=structure_class)\n",
    "\n",
    "    return popt\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "0e2dfe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_tensor_popt_per_combination(structure_class,side=0, plot=save_plot, \n",
    "    peak2peak_data_to_tensor=peak2peak_data_to_tensor,  electrodes_from_listing=electrodes_from_listing,\n",
    "    # roots_recruitment_to_tensor=roots_recruitment_to_tensor, roots_left=roots_left, roots_right=roots_right, \n",
    "    muscles_left=muscles_left, muscles_right=muscles_right\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Function to create tensor with popt values per combination\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    structure_class\n",
    "        muscles or roots \n",
    "    side\n",
    "        default right, set 1 for left\n",
    "    data\n",
    "       tensor with recruitment curves per combination\n",
    "    roots\n",
    "        list of roots\n",
    "    plot\n",
    "        set to 1 if it should be plotted, default 0\n",
    "    \n",
    "    Output\n",
    "    ----------\n",
    "    popt_sigmoid\n",
    "        tensor with optimal parameter for sigmoid fit per combination\n",
    "    \"\"\"\n",
    "    if structure_class==\"muscles\":\n",
    "        if side:\n",
    "            muscle_side=muscles_left\n",
    "        else:\n",
    "            muscle_side=muscles_right\n",
    "\n",
    "        popt_sigmoid=torch.ones(len(electrodes_from_listing),len(muscle_side),4)       \n",
    "        for elec_i in range(len(electrodes_from_listing)):\n",
    "            for muscle_i_one_side in range(len(muscle_side)):\n",
    "                muscle_i=(pd.DataFrame(muscles)[pd.DataFrame(muscles) == muscle_side[muscle_i_one_side]]).dropna().index[0]\n",
    "                popt_sigmoid[elec_i,muscle_i_one_side,:]=torch.tensor(fit_sigmoid_max_value_given(plot,elec_i,muscle_i, structure_class))\n",
    "\n",
    "    if structure_class==\"roots\":\n",
    "        if side:\n",
    "            root_side=roots_left\n",
    "        else:\n",
    "            root_side=roots_right\n",
    "        popt_sigmoid=torch.ones(len(electrodes_from_listing),len(root_side),4)\n",
    "        for elec_i in range(len(electrodes_from_listing)):\n",
    "            for root_i_one_side  in range(len(root_side)):\n",
    "                print(root_side[root_i_one_side])\n",
    "                root_i=(pd.DataFrame(roots)[pd.DataFrame(roots) == root_side[root_i_one_side]]).dropna().index[0]\n",
    "                popt_sigmoid[elec_i,root_i_one_side,:]=torch.tensor(fit_sigmoid_max_value_given(plot, elec_i, root_i, structure_class))\n",
    "\n",
    "    return popt_sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e6d77f",
   "metadata": {},
   "source": [
    "# Neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f66b91",
   "metadata": {},
   "source": [
    "## Loading Neuron Simulation Results\n",
    "Neuron simulations from monopolar electromagnetic (=EM) simulations. (No AF with threshold as it is done for multipolar configurations). \n",
    "Same approach as Rowald*, Komi*, Demesmaeker* et al. 2022.\n",
    "Due to the fact that the code was poorly mantained and not transmited, this part of the pipeline needed to be coded again.\n",
    "\n",
    "Author: Sergio Daniel Hernandez Charpak\n",
    "\n",
    "December 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "31717c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_concatenate_two_string_arrays(array_1,array_2,n_arrays=2,sep_string=\"_\"):\n",
    "\t\"\"\"\n",
    "    Given two arrays of strings, it computes all the different combinations of\n",
    "    arrays[item_array_1, item_array_2] and then form the array of the concatenation\n",
    "    of these two times [item_array_1\"sep\"item_array_2].\n",
    "    @returns array of strings [item_i_array_1\"sep\"item_j_array_2]\n",
    "    \"\"\"\n",
    "\tcomb_array = np.array(np.meshgrid(array_1, array_2)).T.reshape(-1,n_arrays)\n",
    "\tfolders_to_iterate=[]\n",
    "\tfor combination in comb_array:\n",
    "\t\tfolder=\"\"\n",
    "\t\tn_items_to_combine=len(combination)\n",
    "\t\tfolder+=combination[0]\n",
    "\t\tfor i in range(1,n_items_to_combine):\n",
    "\t\t\tfolder+=(sep_string+combination[i])\n",
    "\t\tfolders_to_iterate.append(folder)\n",
    "\treturn folders_to_iterate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338a8dfb",
   "metadata": {},
   "source": [
    "### Exploration\n",
    "We explore one sim and one file to see how it is structred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "9d193db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_new_neurons:\n",
    "\n",
    "    #get folder with simulations\n",
    "    folder_raw_results=location_simulation_file\n",
    "    #Each subfolder (for different lead placement)\n",
    "    # contains the neuron simulation for each monopolar EM simulation.\n",
    "    lead_pos=!ls $folder_raw_results\n",
    "    print(lead_pos)\n",
    "    electrodes=[\"E\"+str(i).zfill(2) for i in range(16)]\n",
    "    folder_raw_results_for_listing=os.path.join(folder_raw_results,'*')\n",
    "    subfolder_list=glob.glob(folder_raw_results_for_listing)\n",
    "    electrodes_from_listing=[folder_i[-3:] for folder_i in subfolder_list]\n",
    "    n_monopolar_sims=len(electrodes_from_listing)\n",
    "\n",
    "    # See how it is structured\n",
    "    i_monopolar_sim=0\n",
    "    monopolar_sim_i=electrodes_from_listing[i_monopolar_sim]\n",
    "    monopolar_sim_sub_folder_i=subfolder_list[i_monopolar_sim]\n",
    "    folder_files_monopolar_sim_sub_folder_i=os.path.join(monopolar_sim_sub_folder_i,'csv')\n",
    "    folder_files_monopolar_sim_sub_folder_i_for_listing=os.path.join(folder_files_monopolar_sim_sub_folder_i,\"*\")\n",
    "    files_monopolar_sim_sub_folder_i=glob.glob(folder_files_monopolar_sim_sub_folder_i_for_listing)\n",
    "    n_total_fibers=len(files_monopolar_sim_sub_folder_i)\n",
    "    i_fiber_sim=0\n",
    "    file_fiber_i_sim=files_monopolar_sim_sub_folder_i[i_fiber_sim]\n",
    "    df_fiber_i_sim=pd.read_csv(file_fiber_i_sim,sep=\",\")\n",
    "    # All fibres per rootlet\n",
    "    df_fiber_i_sim.head(50)\n",
    "    df_fiber_i_sim.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5a6a6e",
   "metadata": {},
   "source": [
    "We are mostly interested by the Tritration factor of each fiber. This is the key value to keep. For each tritration factor, fibers with a tritration factor smaller or equal to this value will count as active. For each factor we can then count the number of fibers active and the number of fibers inactive. These will be the values used to compute the recruitment percentages. \n",
    "\n",
    "In here each file contains the information for each rootlet (10 fibers per rootlet). \n",
    "\n",
    "\n",
    "We now have to :\n",
    "* Get all this information in a dataframe. \n",
    "* Find the maximum overall tritration factor of the simulation (for each monopolar electrode)\n",
    "* Find for each **Root** (not rootlet) the max tritration factor\n",
    "* Do the counting of active fibers and inactive fibers\n",
    "* Compute the recruitment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956f8126",
   "metadata": {},
   "source": [
    "Found the method (implemented by Edoardo/Andreas):\n",
    "```\n",
    "Fiber_List = []\n",
    "for root_idx, root_val in enumerate(Root_Name):\n",
    "    for quad_idx,quad_val in enumerate(Quad_Name):\n",
    "        for type_idx,type_val in enumerate(Type_Name):\n",
    "            Fiber_List.append(root_val + '-' + quad_val + '_' + type_val)\n",
    "\n",
    "for design in designs:\n",
    "    for electrode in electrodes:\n",
    "\n",
    "        filefolder = join(folderpath,design,electrode,'csv')\n",
    "        titration_axes = [] # list holding titration factor from roots\n",
    "        recruitment_percentage = [] # list holding recruitment percentage from roots\n",
    "        for f_1 in Fiber_List:\n",
    "            print f_1\n",
    "            f = join(filefolder,'Titration_Sweeney - '+electrode+'_'+f_1+'.csv')\n",
    "            titration_list = np.genfromtxt(join(filefolder,f), delimiter=',', skip_header=1)\n",
    "            titration_list = titration_list[:,3] #remove later\n",
    "            tdiv = np.linspace(np.min(titration_list), np.max(titration_list), datapoints) #number of data points\n",
    "            rec=[]\n",
    "            for t in tdiv:\n",
    "                cn=0\n",
    "                for tit in titration_list:\n",
    "                    if tit<=t:\n",
    "                        cn+=1\n",
    "                rec.append(cn)\n",
    "            rec=np.array(rec)\n",
    "            percentage_rec = 100.*rec/n\n",
    "\n",
    "            titration_axes.append(tdiv)\n",
    "            recruitment_percentage.append(percentage_rec)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6d010b",
   "metadata": {},
   "source": [
    "### Loading\n",
    "Let us now load everything into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "08eabac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_new_neurons:\n",
    "    ## Define root names\n",
    "    spinal_levels=[\"T12\",\"L1\",\"L2\",\"L3\",\"L4\",\"L5\",\"S1\",\"S2\",\"S3\",\"S4\"]\n",
    "    quadrants=[\"DL\",\"DR\"]\n",
    "    roots=combine_concatenate_two_string_arrays(spinal_levels,quadrants,n_arrays=2,sep_string=\"_\")\n",
    "    n_roots=len(roots)\n",
    "    list_dfs_monopolar_sims=[]\n",
    "\n",
    "    # Loop on the monopolar sims/electrodes\n",
    "    for i_monopolar_sim in range(n_monopolar_sims):\n",
    "        monopolar_sim_i=electrodes_from_listing[i_monopolar_sim]\n",
    "        monopolar_sim_sub_folder_i=subfolder_list[i_monopolar_sim]\n",
    "        folder_files_monopolar_sim_sub_folder_i=os.path.join(monopolar_sim_sub_folder_i,'csv')\n",
    "        folder_files_monopolar_sim_sub_folder_i_for_listing=os.path.join(folder_files_monopolar_sim_sub_folder_i,\"*\")\n",
    "        files_monopolar_sim_sub_folder_i=glob.glob(folder_files_monopolar_sim_sub_folder_i_for_listing)\n",
    "        n_total_fibers=len(files_monopolar_sim_sub_folder_i)\n",
    "        # Loop on the fibers from the file (fibers per rootlet)\n",
    "        for i_fiber_sim in range(n_total_fibers):\n",
    "            file_fiber_i_sim=files_monopolar_sim_sub_folder_i[i_fiber_sim]\n",
    "            df_fiber_i_sim=pd.read_csv(file_fiber_i_sim,sep=\",\")\n",
    "            # Find out which root it belongs to \n",
    "            # Gets a neuron name\n",
    "            name_first_fiber_df_fiber_i_sim= df_fiber_i_sim['Neuron Name'][0]\n",
    "            root_df_fiber_i=\"\"\n",
    "            for root_i in roots:\n",
    "                if root_i in name_first_fiber_df_fiber_i_sim:\n",
    "                    root_df_fiber_i=root_i\n",
    "                    break\n",
    "            df_fiber_i_sim['Root']=root_df_fiber_i\n",
    "            spinal_level_df_fiber_i=\"\"\n",
    "            quadrant_df_fiber_i=\"\"\n",
    "            for spinal_level_i in spinal_levels:\n",
    "                if spinal_level_i in root_df_fiber_i:\n",
    "                    spinal_level_df_fiber_i=spinal_level_i\n",
    "                    break\n",
    "            df_fiber_i_sim['Spinal_Level']=spinal_level_df_fiber_i\n",
    "            for quadrant_i in quadrants:\n",
    "                if quadrant_i in root_df_fiber_i:\n",
    "                    quadrant_df_fiber_i=quadrant_i\n",
    "                    break\n",
    "            df_fiber_i_sim['Quadrant']=quadrant_df_fiber_i\n",
    "            df_fiber_i_sim['EM_Sim']=monopolar_sim_i\n",
    "            list_dfs_monopolar_sims.append(df_fiber_i_sim)\n",
    "    # Concat everything into one df\n",
    "    df_neuron_sim=pd.concat(list_dfs_monopolar_sims,ignore_index=True)\n",
    "\n",
    "    # Save the resulting dataframe\n",
    "    file_name=f\"Neuron_sim_{subject}_{lead}.csv\"\n",
    "    file_path=os.path.join(location_data_dump,file_name)\n",
    "    os.makedirs(location_data_dump,exist_ok=True)\n",
    "    df_neuron_sim.to_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecc4a9f",
   "metadata": {},
   "source": [
    "### Recruitment\n",
    "Now we get the recruitmnet **per root** for each EM_Sim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "5ae44f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save recruitment values per combination  as dict and tensor ##\n",
    "# dict because further processing with dict\n",
    "# tensor if in future want to change all to one style\n",
    "if load_new_neurons:\n",
    "    # save a dict\n",
    "    recruitment_simulation={}\n",
    "    n_data_points=100 # Number of points which represents the \"amplitude\"\n",
    "   \n",
    "    ## create tensor\n",
    "    #electrodes\n",
    "    #roots\n",
    "    #recruitment\n",
    "    roots_recruitment_to_tensor=torch.ones(len(electrodes_from_listing),n_roots,100)\n",
    "    print(roots_recruitment_to_tensor.size())\n",
    "\n",
    "    ## Calculate recruitment ##\n",
    "    # Loop through the monopolar EM simulations ( all the electrodes)\n",
    "    for i_sim in range(n_monopolar_sims):\n",
    "        sim_i=electrodes_from_listing[i_sim]\n",
    "        # Get the results for this particular simulation (=particular electrode)\n",
    "        df_neuron_sim_emSim_i=df_neuron_sim[df_neuron_sim['EM_Sim']==sim_i]\n",
    "        # Get the min and max titration factors for this Neuron simulation\n",
    "        min_trit_factor_sim_i=np.min(df_neuron_sim_emSim_i['Titration Factor'])\n",
    "        max_trit_factor_sim_i=np.max(df_neuron_sim_emSim_i['Titration Factor'])\n",
    "        \n",
    "        # Form the array of titration factors\n",
    "        trit_array_sim_i=np.linspace(min_trit_factor_sim_i,max_trit_factor_sim_i,n_data_points) # n_data_points=100\n",
    "        # Loop through the simulated roots (all roots (L1 - T12))\n",
    "        for i_root in range(n_roots):\n",
    "            root_i=roots[i_root]\n",
    "            # Get the results for this particular root for this particular simulation (5 rootlets for roots, 10 fibres per rootlet (=50 data points))\n",
    "            df_neuron_sim_emSim_i_root_i=df_neuron_sim_emSim_i[df_neuron_sim_emSim_i['Root']==root_i] \n",
    "        \n",
    "            ## Compute the recruitment\n",
    "            # Only get the titration factor\n",
    "            trit_factors_sim_i_root_i=df_neuron_sim_emSim_i_root_i['Titration Factor']\n",
    "            # Prepare the results array\n",
    "            recruitment_sim_i_root_i=np.zeros(np.shape(trit_array_sim_i)) \n",
    "            n_fibers_in_sim_i_root_i=len(trit_factors_sim_i_root_i) # 50, 5rootlets a 10 fibers\n",
    "\n",
    "            # Loop through values of titration between the min and the max of the sim\n",
    "            # activation can be 0 bc min value might be in a different root\n",
    "            # min sim is equals no activation max sim equals max\n",
    "            for i_trit in range(n_data_points): # Number of points which represents the \"amplitude\"\n",
    "                trit_i=trit_array_sim_i[i_trit]\n",
    "                # For a specific root, how many rootlets are activated at certain level (= titration factor) ?\n",
    "                n_active_trit_i= (df_neuron_sim_emSim_i_root_i['Titration Factor'] <= trit_i).sum()\n",
    "                # print(n_active_trit_i)\n",
    "                recruitment_sim_i_root_i[i_trit]=n_active_trit_i\n",
    "            recruitment_sim_i_root_i=recruitment_sim_i_root_i/n_fibers_in_sim_i_root_i\n",
    "\n",
    "            # Prepare the output csv\n",
    "            d_rec_emSim_i_root_i = {'Trit_Array': trit_array_sim_i, 'Recruitment': recruitment_sim_i_root_i}\n",
    "            df_recruitment_emSim_i_root_i = pd.DataFrame(data=d_rec_emSim_i_root_i)\n",
    "            df_recruitment_emSim_i_root_i['Root']=root_i\n",
    "            df_recruitment_emSim_i_root_i['EM_Sim']=sim_i\n",
    "            spinal_level_df_fiber_i=\"\"\n",
    "            quadrant_df_fiber_i=\"\"\n",
    "            for spinal_level_i in spinal_levels:\n",
    "                if spinal_level_i in root_df_fiber_i:\n",
    "                    spinal_level_df_fiber_i=spinal_level_i\n",
    "                    break\n",
    "            df_recruitment_emSim_i_root_i['Spinal_Level']=spinal_level_df_fiber_i\n",
    "            for quadrant_i in quadrants:\n",
    "                if quadrant_i in root_df_fiber_i:\n",
    "                    quadrant_df_fiber_i=quadrant_i\n",
    "                    break\n",
    "            df_recruitment_emSim_i_root_i['Quadrant']=quadrant_df_fiber_i\n",
    "            \n",
    "            ## save in a tensor\n",
    "            # electrode, root, reccruitment\n",
    "            roots_recruitment_to_tensor[i_sim, i_root,:]=torch.tensor(df_recruitment_emSim_i_root_i['Recruitment'].values)\n",
    "\n",
    "            ## Additional ways of saving ##\n",
    "            # save create a class to save it as pickle file instead\n",
    "            recruitment_simulation[f\"_{electrodes_from_listing[i_sim]}_{roots[i_root]}\"] = df_recruitment_emSim_i_root_i\n",
    "        \n",
    "\n",
    "    ## Dump files \n",
    "    #turn into df\n",
    "    df_electrodes_for_roots= pd.DataFrame(electrodes_from_listing, columns =['electrode_name'])\n",
    "    # save as csv\n",
    "    df_electrodes_for_roots.to_csv(location_data_dump+'df_electrodes_for_roots.csv')\n",
    "    # list version ; electrodes_from_listing\n",
    "    \n",
    "    #turn into df\n",
    "    df_roots=pd.DataFrame(roots, columns =['root_name'])\n",
    "    # save as csv                                       \n",
    "    df_roots.to_csv(location_data_dump+'df_roots.csv')\n",
    "    # list version ; roots\n",
    "\n",
    "    # dump pickle file\n",
    "    fh = open(location_data_dump+'recruitment_simulation_to_tensor'+'_'+subject+'.pkl', \"wb\")\n",
    "    pickle.dump(roots_recruitment_to_tensor, fh)\n",
    "    fh.close()\n",
    "    fh = open(location_data_dump+'recruitment_simulation_as_dict'+'_'+subject+'.pkl', \"wb\")\n",
    "    pickle.dump(recruitment_simulation, fh)\n",
    "    fh.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a918de4b",
   "metadata": {},
   "source": [
    "## Retrieve pickle and csv data\n",
    "If present data should be retrieved, set load_new_neurons to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "beb234df",
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_new_neurons==0:\n",
    "\n",
    "\n",
    "\n",
    "    with open(location_data_dump+'recruitment_simulation_to_tensor'+'_'+subject+'.pkl', 'rb') as handle:\n",
    "        roots_recruitment_to_tensor = pickle.load(handle)\n",
    "    with open(location_data_dump+'recruitment_simulation_as_dict'+'_'+subject+'.pkl', 'rb') as handle:\n",
    "            recruitment_simulation = pickle.load(handle)\n",
    "\n",
    "    df_electrodes_for_roots=pd.read_csv(location_data_dump+'df_electrodes_for_roots.csv')\n",
    "    electrodes_from_listing=list(df_electrodes_for_roots[\"electrode_name\"])\n",
    "    df_roots=pd.read_csv(location_data_dump+'df_roots.csv')\n",
    "    roots=list(df_roots[\"root_name\"])\n",
    "    # electrodes=list(electrodes_from_listing)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "d67cff32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate left and right\n",
    "roots_left=['T12_DL','L1_DL','L2_DL','L3_DL','L4_DL','L5_DL','S1_DL','S2_DL','S3_DL','S4_DL']\n",
    "roots_right=['T12_DR','L1_DR','L2_DR','L3_DR','L4_DR','L5_DR','S1_DR','S2_DR','S3_DR','S4_DR']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f488b2",
   "metadata": {},
   "source": [
    "## Plot the simulations (recruitment curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "49cd298e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_recruitment_curve_per_electrode(save_fig=save_plot,recruitment_simulation=recruitment_simulation, electrodes_from_listing=electrodes_from_listing, roots_left=roots_left, roots_right=roots_right):\n",
    "    \"\"\"\n",
    "    A function to create recruitment curves by electrode\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    save_fig\n",
    "        int, set to 1 to save figure\n",
    "    recruitment_simulation\n",
    "        dict with recruitment per electrode root combination,set by default\n",
    "    electrodes_from_listing\n",
    "        list, all ellectrodes used in data, set by default\n",
    "    roots_left, roots_right\n",
    "        list, all roots used in data, separated left and right, set by default\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    legend_title= \"spinal roots\"\n",
    "    xLabel=\"Electric current [a.u]\"\n",
    "    yLabel=\"Afferent recruitment [%]\"\n",
    "\n",
    "    x=np.arange(0, 100)\n",
    "    # Left activation\n",
    "    for electrode in range (len(electrodes_from_listing)):\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.title(f\"Left root activation for {electrodes_from_listing[electrode]} \")\n",
    "        for root in roots_left:\n",
    "            \n",
    "            plt.plot(x,recruitment_simulation[f\"_{electrodes_from_listing[electrode]}_{root}\"][\"Recruitment\"], label=root)\n",
    "            plt.legend(title=legend_title)\n",
    "            plt.xlabel(xLabel)\n",
    "            plt.ylabel(yLabel)\n",
    "\n",
    "            if save_fig:\n",
    "                print(\"figure is saved\")\n",
    "                data_file = electrodes_from_listing[electrode]+\"_\"+\"recruitment_curve\"+'.png'\n",
    "                save_figure(folder_name=\"Recruitment_curve/roots\", data_file=data_file)\n",
    "            \n",
    "        plt.show()\n",
    "\n",
    "    # Right activation\n",
    "    for electrode in range (len(electrodes_from_listing)):\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.title(f\"Right root activation for {electrodes_from_listing[electrode]} \")\n",
    "        for root in roots_right:\n",
    "            \n",
    "            plt.plot(x,recruitment_simulation[f\"_{electrodes_from_listing[electrode]}_{root}\"][\"Recruitment\"], label=root)\n",
    "            plt.legend(title=legend_title)\n",
    "            plt.xlabel(xLabel)\n",
    "            plt.ylabel(yLabel)\n",
    "            if save_fig:\n",
    "                data_file = electrodes_from_listing[electrode]+\"_\"+\"recruitment_curve\"+'.png'\n",
    "                save_figure(folder_name=\"Recruitment_curve/roots\", data_file=data_file)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "1841f71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_plot:\n",
    "    get_recruitment_curve_per_electrode(save_fig=save_plot)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "27fe236c",
   "metadata": {},
   "source": [
    "## Build Heat map\n",
    "The difficulty here is to get from a curve to a number to feed into the heatmap.\n",
    "These are the different techniques/possibilites\n",
    "(Choose the applying one in section: heatmap indiviudal roots -> plot the heatmap, function: get_heat_map_individual_root_recruitment)\n",
    "\n",
    "- get_number_for_heat_map_100_electric_current_normalise_by_max_root_response\n",
    "- get_number_for_heat_map_100_electric_current \n",
    "- 1-[divide(root_elec_i_electric_current_at _100%,   overall_max_electric current_at_100%_root)] (to be coded)\n",
    "\n",
    "\n",
    "\n",
    "For now the computation of the number to make a heatmap electrodes/roots \n",
    "we do one approach by taking the  electric current at the point where afferent recruitment reaches 100%.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6886cbc",
   "metadata": {},
   "source": [
    "### Normalisation/ Get nr for the heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "14a45121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_for_heat_map_100_electric_current_normalise_by_max_root_response(electrodes_from_listing=electrodes_from_listing, roots=roots, recruitment_simulation= recruitment_simulation):\n",
    "\n",
    "    \"\"\"\n",
    "    A function to get the number for the heatmap by by taking the  electric current \n",
    "    at the point where afferent recruitment reaches 100%.\n",
    "    substracting this electric current from 100 \n",
    "    and dividing it by the max muscle response for a muscle\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    electrodes_from_listing\n",
    "        list, names of electrodes\n",
    "    roots\n",
    "        list, names of root\n",
    "    recruitment_simulation\n",
    "        dict with recruitment per electrode root combination,set by default\n",
    "  \n",
    "    Output\n",
    "    ----------\n",
    "    data_normalised_df\n",
    "        df of values \"normalised\"\n",
    "    \"\"\"\n",
    "    electric_current=np.zeros((len(roots),len(electrodes_from_listing)))\n",
    "    for root_i in range(0, len(roots)):\n",
    "        for elec_i in range (0, len(electrodes_from_listing)):\n",
    "            # extract first index where recruitment =1.0\n",
    "            # substract it from 100, since lower values in elec current show higher activation -> turn it\n",
    "            electric_current[root_i ][elec_i]= 100-recruitment_simulation[f\"_{electrodes_from_listing[elec_i]}_{roots[root_i]}\"][\"Recruitment\"][np.where(1==recruitment_simulation[f\"_{electrodes_from_listing[elec_i]}_{roots[root_i]}\"][\"Recruitment\"])[0]].index[0]\n",
    "            \n",
    "    ## turn into a df\n",
    "    # electric_current_df= pd.DataFrame(electric_current, columns=df_electrodes_for_roots[\"electrode_name\"], index=df_roots[\"root_name\"])\n",
    "    electric_current_df= pd.DataFrame(electric_current, columns=df_electrodes_for_roots[\"electrode_name\"], index=df_roots[\"root_name\"])\n",
    "    ##per root normalise it by max root response\n",
    "    for root_i in roots:\n",
    "        max_value_for_root=np.nanmax(electric_current_df.loc[root_i])\n",
    "        electric_current_df.loc[root_i]=np.divide(electric_current_df.loc[root_i], max_value_for_root)\n",
    "\n",
    "    print(\"normalisation method is: (100-electric_current)_normalise_by_max_root_response\")\n",
    "    return electric_current_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "dabbf3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_for_heat_map_100_electric_current(electrodes_from_listing=electrodes_from_listing, roots=roots, recruitment_simulation= recruitment_simulation):\n",
    "\n",
    "    \"\"\"\n",
    "    A function to get the number for the heatmap by by taking the  electric current \n",
    "    at the point where afferent recruitment reaches 100%.\n",
    "    substracting this electric current from 100 \n",
    "    and dividing it by the max muscle response for a muscle\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    electrodes_from_listing\n",
    "        list, names of electrodes\n",
    "    roots\n",
    "        list, names of root\n",
    "    recruitment_simulation\n",
    "        dict with recruitment per electrode root combination,set by default\n",
    "  \n",
    "    Output\n",
    "    ----------\n",
    "    data_normalised_df\n",
    "        df of values \"normalised\"\n",
    "    \"\"\"\n",
    "    electric_current=np.zeros((len(roots),len(electrodes_from_listing)))\n",
    "    for root_i in range(0, len(roots)):\n",
    "        for elec_i in range (0, len(electrodes_from_listing)):\n",
    "            # extract first index where recruitment =1.0\n",
    "            # substract it from 100, since lower values in elec current show higher activation -> turn it\n",
    "            electric_current[root_i ][elec_i]= 100-recruitment_simulation[f\"_{electrodes_from_listing[elec_i]}_{roots[root_i]}\"][\"Recruitment\"][np.where(1==recruitment_simulation[f\"_{electrodes_from_listing[elec_i]}_{roots[root_i]}\"][\"Recruitment\"])[0]].index[0]\n",
    "            \n",
    "    ## turn into a df\n",
    "    electric_current_df= pd.DataFrame(electric_current, columns=df_electrodes_for_roots[\"electrode_name\"], index=df_roots[\"root_name\"])\n",
    "\n",
    "    print(\"normalisation method is: 100-electric_current\")\n",
    "    return electric_current_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fcfdc2",
   "metadata": {},
   "source": [
    "### Heat map all roots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "b5cd96e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_heatmap_all_roots_overview(save_fig=save_plot, roots=roots, electrodes_from_listing=electrodes_from_listing):\n",
    "    \"\"\"\n",
    "    A function to create a heatmap.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    save_fig\n",
    "        int, if set to 1 save figure\n",
    "    roots\n",
    "        list of all the muscles in the gait, set by default\n",
    "    electrodes_from_listing\n",
    "        list of all the electrodes used, set by default\n",
    "    \"\"\"\n",
    "            \n",
    "    fig, ax = plt.subplots(figsize=(15,10))# creating subplot\n",
    "\n",
    "    ## Define which normalisation method is used\n",
    "    data=get_number_for_heat_map_100_electric_current_normalise_by_max_root_response()\n",
    "    data_structure=\"100-electric_current_div_max_root_response\"\n",
    "    # data=get_number_for_heat_map_100_electric_current()\n",
    "    # data_structure=\"100-electric_current\"\n",
    "    \n",
    "    ## Define heatmap\n",
    "    sns.heatmap(data=data, cmap=\"Reds\", cbar=True,\n",
    "    annot=True,  yticklabels=roots,\n",
    "    xticklabels=electrodes_from_listing,\n",
    "    cbar_kws={'label': f\"Root activation [a.u]\"},\n",
    "    fmt='.2g' )\n",
    " \n",
    "    ## Define ticks\n",
    "    plt.tick_params(axis='both', which='major', labelsize=10, labelbottom = False, bottom=False, top = False, labeltop=True)\n",
    "\n",
    "    ## Define labels\n",
    "    ax.set_title('Heat map for root activation per electrode', size=18, fontstyle='italic', pad=20)\n",
    "    ax.set_ylabel('Roots',  size=12, fontstyle='italic', labelpad=10, color=\"grey\", fontweight=\"bold\") \n",
    "    ax.xaxis.set_label_position('top') \n",
    "    ax.set_xlabel('Electrodes', size=12, fontstyle='italic', labelpad=10, color=\"grey\", fontweight=\"bold\")\n",
    "\n",
    "    \n",
    "    ## Define Textbox\n",
    "    print(f\"Heat map is being created with Normalisation method: {data_structure}\")\n",
    "    axbox = fig.add_axes([0, 1.0, 0.2, 0.05]) #[left, bottom, width, height]\n",
    "    text_box = TextBox(axbox,label=None, textalignment=\"center\")\n",
    "    text_box.set_val(data_structure)  # Trigger `submit` with the initial string.\n",
    "\n",
    "    ## Save plots   \n",
    "    if save_fig:\n",
    "        folder_name= \"heatmap/muscles\"\n",
    "        data_file = \"Heat_map_all_muscles_\"+ data_structure+'_'+subject+'.png'\n",
    "        save_figure(folder_name, data_file)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "a5a810f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_plot:\n",
    "    get_heatmap_all_roots_overview()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd85a42d",
   "metadata": {},
   "source": [
    "### Heat map indiviudal roots, paddle lead arrangement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e307e73e",
   "metadata": {},
   "source": [
    "#### Functions for the heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "e7041580",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Interpolate unknown values in the heat map ###\n",
    "\n",
    "def interpolate_missing_pixels(image, mask, method, fill_value=0):\n",
    "\n",
    "    \"\"\"\n",
    "    A function to interpolate missing values.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image \n",
    "        2D np.array\n",
    "    mask\n",
    "        a 2D boolean array, True indicates missing values\n",
    "    method\n",
    "        interpolation method, one of 'nearest', 'linear', 'cubic'.\n",
    "    fill_value\n",
    "        which value to use for filling up data outside the\n",
    "        convex hull of known pixel values.\n",
    "        Default is 0, Has no effect for 'nearest'.\n",
    "        \n",
    "    Return\n",
    "    ----------\n",
    "    interp_image\n",
    "        nd.array with missing values interpolated\n",
    "    \"\"\"\n",
    "\n",
    "    h, w = image.shape[:2]\n",
    "    xx, yy = np.meshgrid(np.arange(w), np.arange(h))\n",
    "\n",
    "    known_x = xx[~mask]\n",
    "    known_y = yy[~mask]\n",
    "    known_v = image[~mask]\n",
    "    missing_x = xx[mask]\n",
    "    missing_y = yy[mask]\n",
    "\n",
    "    interp_values = interpolate.griddata(\n",
    "        (known_x, known_y), known_v, (missing_x, missing_y),\n",
    "        method=method, fill_value=fill_value\n",
    "    )\n",
    "\n",
    "    interp_image = image.copy()\n",
    "    interp_image[missing_y, missing_x] = interp_values\n",
    "\n",
    "    return interp_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "4361d995",
   "metadata": {},
   "outputs": [],
   "source": [
    "### text to define electrodes in plot\n",
    "text = np.array([\n",
    "['', '','', '','', '', '', '', ''], ['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],\n",
    "['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],\n",
    "['', '','', '','1', '', '', '', ''],['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],\n",
    "['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],\n",
    "['', '','', '','', '', '', '', ''],['', '7','', '','', '', '', '13', ''],['', '','', '','', '', '', '', ''],\n",
    "['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],\n",
    "['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],\n",
    "['', '','', '','0', '', '', '', ''],['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],\n",
    "['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],\n",
    "['', '','', '','', '', '', '', ''],['', '6','', '','', '', '', '12', ''],['', '','', '','', '', '', '', ''],\n",
    "['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],\n",
    "['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],['', '','', '','15', '', '', '', ''],\n",
    "['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],\n",
    "['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],\n",
    "['', '','', '','', '', '', '', ''], ['', '5','', '','', '', '', '11', ''],['', '','', '','', '', '', '', ''],\n",
    "['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],\n",
    "['', '','', '','', '', '', '', ''],['', '','', '','14', '', '', '', ''],['', '','', '','', '', '', '', ''],\n",
    "['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],\n",
    "['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],['', '4','', '','', '', '', '10', ''],\n",
    "['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],\n",
    "['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],\n",
    "['', '','', '','', '', '', '', ''], ['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],\n",
    "['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],\n",
    "['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],['', '3','', '2','', '8', '', '9', ''],\n",
    "['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],\n",
    "['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],\n",
    "['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', ''],\n",
    "['', '','', '','', '', '', '', ''],['', '','', '','', '', '', '', '']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "c603e128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify image\n",
    "def get_cropped_image(location_image=location_image, lead=0, spinalcord=0):\n",
    "    \"\"\"\n",
    "    Function to crop the paddle lead image\n",
    "\n",
    "    location_image\n",
    "        directory of image\n",
    "    Define which image\n",
    "        lead\n",
    "            image of the paddle lead, zero by default\n",
    "        spinalcord\n",
    "            image of the spinal cord, zero by default\n",
    "    \"\"\"\n",
    "    if lead:\n",
    "        # Opens a image in RGB mode\n",
    "        load_image=os.path.join(location_image,\"lead.png\")\n",
    "        # Setting the points for cropped image\n",
    "        left = np.divide(513-323, 2)\n",
    "        top=55\n",
    "        right = left+323\n",
    "        bottom = top+1874\n",
    "        \n",
    "    if spinalcord:\n",
    "        # Opens a image in RGB mode\n",
    "        load_image=os.path.join(location_image,\"Spinal_cord.png\")\n",
    "        # Setting the points for cropped image\n",
    "        left = 123\n",
    "        top = 18\n",
    "        right = 123+157\n",
    "        bottom = 18+679\n",
    "    \n",
    "    # Cropped image of above dimension\n",
    "    # (It will not change original image)\n",
    "    im = Image.open(load_image)\n",
    "    im1 = im.crop((left, top, right, bottom))\n",
    "    \n",
    "    # Shows the image in image viewer\n",
    "    return im1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ecb40f",
   "metadata": {},
   "source": [
    "#### Plot the heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "a9303ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_heat_map_individual_root_recruitment(interpolation=0, save_fig=save_plot, interpol_method='cubic', text=text, roots=roots, electrodes=electrodes_from_listing):\n",
    "    \"\"\"\n",
    "    A function to create a heatmap  with and without interpolation.\n",
    "    -Interpolation method can be adapted 'nearest', 'linear', 'cubic', by changing the interpolation function\n",
    "    -data fed to the heatmap can be adapted by changing normalisation method\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    interpolation\n",
    "        int, if set to one, generates heat maps with interpolation, 0 by default\n",
    "    save_fig\n",
    "        int, if set to 1 save figure, 0 by default\n",
    "    interpol_method\n",
    "        interpolation method, one of 'nearest', 'linear', 'cubic'\n",
    "    text\n",
    "        array used for annotation; to define electrodes in the plot\n",
    "    roots\n",
    "        list of all the roots in the gait, set by default ('T12_DL', 'T12_DR', 'L1_DL'...)\n",
    "    electrodes\n",
    "        list of all the electrodes used, set by default ('E00', 'E01', 'E02'...)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "   ## Define which normalisation method is used ##\n",
    "    data=get_number_for_heat_map_100_electric_current()\n",
    "    data_structure=\"100-electric_current\"\n",
    "    # data=get_number_for_heat_map_100_electric_current_normalise_by_max_root_response() # this wont work well bc interpolation doesnt work between 0 and 1\n",
    "    # data_structure=\"100-electric_current_div_max_root_response\"\n",
    "   \n",
    "\n",
    "\n",
    "    ## Define paddle lead\n",
    "    if interpolation:\n",
    "        print(\"Heat map s being interpolated\")\n",
    "        # Build tensor filled with -1, thus undefined values are easily recognisable ##    \n",
    "        paddle_lead =np.zeros(80* 9)\n",
    "        paddle_lead=np.array([-1]*len(paddle_lead))\n",
    "        paddle_lead=paddle_lead.reshape((80,9))\n",
    "        method=\"interpolated\"\n",
    "\n",
    "    else:\n",
    "        print(\"No interpoaltion is used for the heat map\")\n",
    "        method=\"non_interpolated\"\n",
    "        paddle_lead =np.zeros(80* 9)\n",
    "        paddle_lead=paddle_lead.reshape((80,9))\n",
    "\n",
    "    ## Get the lead image as an array so we can plot it ##\n",
    "    map_img=get_cropped_image(lead=1)\n",
    "    ## For every root fill paddle lead with values ##\n",
    "    for root in roots:\n",
    "        # Set settings for plot ## \n",
    "        fig, ax = plt.subplots(figsize=(3,10))# creating subplot\n",
    "        # Set title\n",
    "        ax.set_title(f\"{method} heat map for {root}\", size=18, fontstyle='italic', pad=20)\n",
    "    \n",
    "        # Define electrode placements\n",
    "        numbers=[1, 0, 15, 14]\n",
    "        for index, number in enumerate(numbers, start=0): \n",
    "            n=(14*index)+3 # equal spacing\n",
    "            row=4\n",
    "            e=number\n",
    "            #save the same value for all the pixels in the electrode\n",
    "            for i in range(6):\n",
    "                    paddle_lead[i+n][row] =data.loc[root, electrodes[e]]\n",
    "                    # print(i+n)\n",
    "\n",
    "        numbers=[7, 6, 5, 4]\n",
    "        for index, number in enumerate(numbers, start=0):  \n",
    "            n=(14*index)+10 # equal spacing\n",
    "            row=1\n",
    "            e=number\n",
    "            #save the same value for all the pixels in the electrode\n",
    "            for i in range(6):\n",
    "            \n",
    "                    paddle_lead[i+n][row] =data.loc[root, electrodes[e]]\n",
    "\n",
    "        numbers=[13, 12, 11, 10]\n",
    "        for index, number in enumerate(numbers, start=0):   \n",
    "            n=(14*index)+10 # equal spacing\n",
    "            row=7\n",
    "            e=number\n",
    "            #save the same value for all the pixels in the electrode\n",
    "            for i in range(6):\n",
    "                    paddle_lead[i+n][row] =data.loc[root, electrodes[e]]\n",
    "\n",
    "        numbers=[3, 2, 8, 9]\n",
    "        for index, number in enumerate(numbers, start=0):  \n",
    "            n=55+10\n",
    "            row=1+(index*2)\n",
    "            e=number\n",
    "            #save the same value for all the pixels in the electrode\n",
    "            for i in range(6):\n",
    "                    paddle_lead[i+n][row] =data.loc[root, electrodes[e]]\n",
    "        \n",
    "        if interpolation:\n",
    "            # interpolate unknown values\n",
    "            # Create boolean, with true for the unknown values, which were set to -1, for interpolation #\n",
    "            mask=paddle_lead<0\n",
    "\n",
    "            ## Get interpolation for the unknown values ##\n",
    "            interpolated_image=interpolate_missing_pixels(\n",
    "            image=paddle_lead,\n",
    "            mask=mask,\n",
    "            method=interpol_method,\n",
    "            fill_value= 0\n",
    "            )\n",
    "\n",
    "            ## Set values outside of lead to zero ##\n",
    "            # do it after interpolation that this doent get taken into account for interpol\n",
    "            nr_columns=[8, 4, 2, 1, 1, 1, 2, 4, 8]\n",
    "            for index, columns in enumerate(nr_columns):\n",
    "                for col in range(0, columns):\n",
    "                        interpolated_image[col][0+index] =0\n",
    "\n",
    "            nr_columns=[7, 5,4, 4, 4, 4,4, 5, 7]\n",
    "            for index, columns in enumerate(nr_columns):\n",
    "                for col in range(79, 79-columns, -1):\n",
    "                        interpolated_image[col][0+index] =0\n",
    "\n",
    "            \n",
    "        ## Drawing heatmap on current axes ##\n",
    "        if interpolation:\n",
    "            hmax= sns.heatmap(\n",
    "                data=interpolated_image, annot=text, fmt=\"\",\n",
    "                cmap=LinearSegmentedColormap.from_list('', ['white', 'r']),\n",
    "                cbar_kws={'label': \"Muscle activation [V/A]\"},\n",
    "                yticklabels=False, xticklabels=False, vmin=0, \n",
    "                vmax=100, \n",
    "                alpha = 0.75, # whole heatmap is translucent\n",
    "                zorder = 2,\n",
    "                    )\n",
    "        else:\n",
    "            hmax= sns.heatmap(\n",
    "            data=paddle_lead, annot=text, fmt=\"\",\n",
    "            cmap=LinearSegmentedColormap.from_list('', ['white', 'r']),\n",
    "            cbar_kws={'label': \"Muscle activation [V/A]\"},\n",
    "            yticklabels=False, xticklabels=False, vmin=0, \n",
    "            vmax=100, \n",
    "            alpha = 0.75, # whole heatmap is translucent\n",
    "            zorder = 2,\n",
    "                )\n",
    "        \n",
    "        ## put the image under the heatmap\n",
    "        hmax.imshow(map_img,\n",
    "            aspect = hmax.get_aspect(),\n",
    "            extent =hmax.get_xlim() + hmax.get_ylim(),\n",
    "            zorder = 1) \n",
    "        \n",
    "        # ## Define Textbox\n",
    "        # axbox = fig.add_axes([-0.5, 1.0, 1., 0.05]) #[left, bottom, width, height]\n",
    "        # text_box = TextBox(axbox,label=None, textalignment=\"center\")\n",
    "        # text_box.set_val(data_structure)  # Trigger `submit` with the initial string.\n",
    "\n",
    "        ## Save plots \n",
    "        if save_fig:\n",
    "            folder_name= f\"heatmap/roots/{method}/{data_structure}\"\n",
    "            data_file =root+\"_\"+\"heat_map\"+'_'+subject+'.png'\n",
    "            save_figure(folder_name, data_file)\n",
    "        show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c33ff1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_plot:\n",
    "    get_heat_map_individual_root_recruitment(save_fig=0, interpolation=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0eec191",
   "metadata": {},
   "source": [
    "## Evaluation preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdc3d87",
   "metadata": {},
   "source": [
    "define which matrices to export for the evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "72fbfe55",
   "metadata": {},
   "source": [
    "### heat map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "06b641ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### muscles\n",
    "# dat=set_normalisation_by_max_response()\n",
    "# #between 0 and 1\n",
    "# matrix_muscles_df=set_normalisation_by_max_response()\n",
    "# matrix_muscles_df.to_csv('/Volumes/Extreme_SSD/Projectome_Estimation/evaluation_data/matrix_muscle_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "b7fda326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### roots\n",
    "\n",
    "# # between 0 and 1\n",
    "# matrix_roots_df=get_number_for_heat_map_100_electric_current_normalise_by_max_root_response()\n",
    "# matrix_roots_df.to_csv(location_data_dump+'matrix_roots_df.csv')\n",
    "\n",
    "# # # between 0 and 100\n",
    "# # matrix_roots=get_number_for_heat_map_100_electric_current()\n",
    "# # matrix_roots_df.to_csv('/Volumes/Extreme_SSD/Projectome_Estimation/evaluation_data/matrix_roots_df.csv')\n",
    "\n",
    "# ## for simgoid curves get \n",
    "# matrix_parameters_root_df=1\n",
    "# matrix_parameters_root_df.to_csv(location_data_dump+'matrix_parameters_root_df.csv')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4fd86da7",
   "metadata": {},
   "source": [
    "### Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b023ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "muscles_popt_sigmoid_right=get_tensor_popt_per_combination(structure_class=\"muscles\", side=0, plot=0)\n",
    "muscles_popt_sigmoid_right=get_tensor_popt_per_combination(structure_class=\"muscles\", side=1, plot=0)\n",
    "roots_popt_sigmoid_right=get_tensor_popt_per_combination(structure_class=\"roots\", side=0, plot=0)\n",
    "roots_popt_sigmoid_right=get_tensor_popt_per_combination(structure_class=\"roots\", side=1, plot=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('projectome_finder')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "f932c8e077b341d20504a7add15d58d55a3a6203500067dcddea991ea8b4378e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
