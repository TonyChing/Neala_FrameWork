{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e6a334de",
   "metadata": {},
   "outputs": [],
   "source": [
    "## set personal saving/ retrieving configuration\n",
    "# define simulation is retrieved from (csv file)\n",
    "location_simulation_file='/Volumes/Extreme_SSD/Projectome_finder/Projectome_Estimation/senn_single_pulse'\n",
    "## Set subject and lead position\n",
    "subject='MR012'\n",
    "lead='GO2'\n",
    "\n",
    "#define location where plots should be saved\n",
    "location_save_plots='/Users/nealarohner/Desktop/Projectome_Finder/code/Neala_Master_Thesis/plots/{subject}/'\n",
    "os.makedirs(location_save_plots,exist_ok=True)\n",
    "## if new neuron simulations should be loaded else dataset will be retrieved\n",
    "#define location where data should be saved\n",
    "location_data_dump=f'/Volumes/Extreme_SSD/Projectome_finder/CSV_and_pickle/{subject}/'\n",
    "os.makedirs(location_data_dump,exist_ok=True)\n",
    "# set to 1\n",
    "load_new_neurons=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e6d77f",
   "metadata": {},
   "source": [
    "# Neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f66b91",
   "metadata": {},
   "source": [
    "## Loading Neuron Simulation Results\n",
    "Neuron simulations from monopolar electromagnetic (=EM) simulations. (No AF with threshold as it is done for multipolar configurations). \n",
    "Same approach as Rowald*, Komi*, Demesmaeker* et al. 2022.\n",
    "Due to the fact that the code was poorly mantained and not transmited, this part of the pipeline needed to be coded again.\n",
    "\n",
    "Author: Sergio Daniel Hernandez Charpak\n",
    "\n",
    "December 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bce2c19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc5f8f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load and save files\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "# to form the table\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31717c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_concatenate_two_string_arrays(array_1,array_2,n_arrays=2,sep_string=\"_\"):\n",
    "\t\"\"\"\n",
    "    Given two arrays of strings, it computes all the different combinations of\n",
    "    arrays[item_array_1, item_array_2] and then form the array of the concatenation\n",
    "    of these two times [item_array_1\"sep\"item_array_2].\n",
    "    @returns array of strings [item_i_array_1\"sep\"item_j_array_2]\n",
    "    \"\"\"\n",
    "\tcomb_array = np.array(np.meshgrid(array_1, array_2)).T.reshape(-1,n_arrays)\n",
    "\tfolders_to_iterate=[]\n",
    "\tfor combination in comb_array:\n",
    "\t\tfolder=\"\"\n",
    "\t\tn_items_to_combine=len(combination)\n",
    "\t\tfolder+=combination[0]\n",
    "\t\tfor i in range(1,n_items_to_combine):\n",
    "\t\t\tfolder+=(sep_string+combination[i])\n",
    "\t\tfolders_to_iterate.append(folder)\n",
    "\treturn folders_to_iterate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338a8dfb",
   "metadata": {},
   "source": [
    "### Exploration\n",
    "We explore one sim and one file to see how it is structred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d193db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_new_neurons:\n",
    "\n",
    "    #get folder with simulations\n",
    "    folder_raw_results=location_simulation_file\n",
    "    #Each subfolder (for different lead placement)\n",
    "    # contains the neuron simulation for each monopolar EM simulation.\n",
    "    lead_pos=!ls $folder_raw_results\n",
    "    print(lead_pos)\n",
    "    electrodes=[\"E\"+str(i).zfill(2) for i in range(16)]\n",
    "    folder_raw_results_for_listing=os.path.join(folder_raw_results,'*')\n",
    "    subfolder_list=glob.glob(folder_raw_results_for_listing)\n",
    "    electrodes_from_listing=[folder_i[-3:] for folder_i in subfolder_list]\n",
    "    n_monopolar_sims=len(electrodes_from_listing)\n",
    "\n",
    "    # See how it is structured\n",
    "    i_monopolar_sim=0\n",
    "    monopolar_sim_i=electrodes_from_listing[i_monopolar_sim]\n",
    "    monopolar_sim_sub_folder_i=subfolder_list[i_monopolar_sim]\n",
    "    folder_files_monopolar_sim_sub_folder_i=os.path.join(monopolar_sim_sub_folder_i,'csv')\n",
    "    folder_files_monopolar_sim_sub_folder_i_for_listing=os.path.join(folder_files_monopolar_sim_sub_folder_i,\"*\")\n",
    "    files_monopolar_sim_sub_folder_i=glob.glob(folder_files_monopolar_sim_sub_folder_i_for_listing)\n",
    "    n_total_fibers=len(files_monopolar_sim_sub_folder_i)\n",
    "    i_fiber_sim=0\n",
    "    file_fiber_i_sim=files_monopolar_sim_sub_folder_i[i_fiber_sim]\n",
    "    df_fiber_i_sim=pd.read_csv(file_fiber_i_sim,sep=\",\")\n",
    "    # All fibres per rootlet\n",
    "    df_fiber_i_sim.head(50)\n",
    "    df_fiber_i_sim.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5a6a6e",
   "metadata": {},
   "source": [
    "We are mostly interested by the Tritration factor of each fiber. This is the key value to keep. For each tritration factor, fibers with a tritration factor smaller or equal to this value will count as active. For each factor we can then count the number of fibers active and the number of fibers inactive. These will be the values used to compute the recruitment percentages. \n",
    "\n",
    "In here each file contains the information for each rootlet (10 fibers per rootlet). \n",
    "\n",
    "\n",
    "We now have to :\n",
    "* Get all this information in a dataframe. \n",
    "* Find the maximum overall tritration factor of the simulation (for each monopolar electrode)\n",
    "* Find for each **Root** (not rootlet) the max tritration factor\n",
    "* Do the counting of active fibers and inactive fibers\n",
    "* Compute the recruitment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956f8126",
   "metadata": {},
   "source": [
    "Found the method (implemented by Edoardo/Andreas):\n",
    "```\n",
    "Fiber_List = []\n",
    "for root_idx, root_val in enumerate(Root_Name):\n",
    "    for quad_idx,quad_val in enumerate(Quad_Name):\n",
    "        for type_idx,type_val in enumerate(Type_Name):\n",
    "            Fiber_List.append(root_val + '-' + quad_val + '_' + type_val)\n",
    "\n",
    "for design in designs:\n",
    "    for electrode in electrodes:\n",
    "\n",
    "        filefolder = join(folderpath,design,electrode,'csv')\n",
    "        titration_axes = [] # list holding titration factor from roots\n",
    "        recruitment_percentage = [] # list holding recruitment percentage from roots\n",
    "        for f_1 in Fiber_List:\n",
    "            print f_1\n",
    "            f = join(filefolder,'Titration_Sweeney - '+electrode+'_'+f_1+'.csv')\n",
    "            titration_list = np.genfromtxt(join(filefolder,f), delimiter=',', skip_header=1)\n",
    "            titration_list = titration_list[:,3] #remove later\n",
    "            tdiv = np.linspace(np.min(titration_list), np.max(titration_list), datapoints) #number of data points\n",
    "            rec=[]\n",
    "            for t in tdiv:\n",
    "                cn=0\n",
    "                for tit in titration_list:\n",
    "                    if tit<=t:\n",
    "                        cn+=1\n",
    "                rec.append(cn)\n",
    "            rec=np.array(rec)\n",
    "            percentage_rec = 100.*rec/n\n",
    "\n",
    "            titration_axes.append(tdiv)\n",
    "            recruitment_percentage.append(percentage_rec)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6d010b",
   "metadata": {},
   "source": [
    "### Loading\n",
    "Let us now load everything into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "08eabac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_new_neurons:\n",
    "    ## Define root names\n",
    "    spinal_levels=[\"T12\",\"L1\",\"L2\",\"L3\",\"L4\",\"L5\",\"S1\",\"S2\",\"S3\",\"S4\"]\n",
    "    quadrants=[\"DL\",\"DR\"]\n",
    "    roots=combine_concatenate_two_string_arrays(spinal_levels,quadrants,n_arrays=2,sep_string=\"_\")\n",
    "    n_roots=len(roots)\n",
    "    list_dfs_monopolar_sims=[]\n",
    "\n",
    "    # Loop on the monopolar sims/electrodes\n",
    "    for i_monopolar_sim in range(n_monopolar_sims):\n",
    "        monopolar_sim_i=electrodes_from_listing[i_monopolar_sim]\n",
    "        monopolar_sim_sub_folder_i=subfolder_list[i_monopolar_sim]\n",
    "        folder_files_monopolar_sim_sub_folder_i=os.path.join(monopolar_sim_sub_folder_i,'csv')\n",
    "        folder_files_monopolar_sim_sub_folder_i_for_listing=os.path.join(folder_files_monopolar_sim_sub_folder_i,\"*\")\n",
    "        files_monopolar_sim_sub_folder_i=glob.glob(folder_files_monopolar_sim_sub_folder_i_for_listing)\n",
    "        n_total_fibers=len(files_monopolar_sim_sub_folder_i)\n",
    "        # Loop on the fibers from the file (fibers per rootlet)\n",
    "        for i_fiber_sim in range(n_total_fibers):\n",
    "            file_fiber_i_sim=files_monopolar_sim_sub_folder_i[i_fiber_sim]\n",
    "            df_fiber_i_sim=pd.read_csv(file_fiber_i_sim,sep=\",\")\n",
    "            # Find out which root it belongs to \n",
    "            # Gets a neuron name\n",
    "            name_first_fiber_df_fiber_i_sim= df_fiber_i_sim['Neuron Name'][0]\n",
    "            root_df_fiber_i=\"\"\n",
    "            for root_i in roots:\n",
    "                if root_i in name_first_fiber_df_fiber_i_sim:\n",
    "                    root_df_fiber_i=root_i\n",
    "                    break\n",
    "            df_fiber_i_sim['Root']=root_df_fiber_i\n",
    "            spinal_level_df_fiber_i=\"\"\n",
    "            quadrant_df_fiber_i=\"\"\n",
    "            for spinal_level_i in spinal_levels:\n",
    "                if spinal_level_i in root_df_fiber_i:\n",
    "                    spinal_level_df_fiber_i=spinal_level_i\n",
    "                    break\n",
    "            df_fiber_i_sim['Spinal_Level']=spinal_level_df_fiber_i\n",
    "            for quadrant_i in quadrants:\n",
    "                if quadrant_i in root_df_fiber_i:\n",
    "                    quadrant_df_fiber_i=quadrant_i\n",
    "                    break\n",
    "            df_fiber_i_sim['Quadrant']=quadrant_df_fiber_i\n",
    "            df_fiber_i_sim['EM_Sim']=monopolar_sim_i\n",
    "            list_dfs_monopolar_sims.append(df_fiber_i_sim)\n",
    "    # Concat everything into one df\n",
    "    df_neuron_sim=pd.concat(list_dfs_monopolar_sims,ignore_index=True)\n",
    "\n",
    "    # Save the resulting dataframe\n",
    "    file_name=f\"Neuron_sim_{subject}_{lead}.csv\"\n",
    "    file_path=os.path.join(location_data_dump,file_name)\n",
    "    os.makedirs(location_data_dump,exist_ok=True)\n",
    "    df_neuron_sim.to_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecc4a9f",
   "metadata": {},
   "source": [
    "### Recruitment\n",
    "Now we get the recruitmnet **per root** for each EM_Sim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5ae44f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save recruitment values per combination  as dict and tensor ##\n",
    "# dict because further processing with dict\n",
    "# tensor if in future want to change all to one style\n",
    "if load_new_neurons:\n",
    "    # save a dict\n",
    "    recruitment_simulation={}\n",
    "    n_data_points=100 # Number of points which represents the \"amplitude\"\n",
    "   \n",
    "    ## create tensor\n",
    "    #electrodes\n",
    "    #roots\n",
    "    #recruitment\n",
    "    roots_simulation_to_tensor=torch.ones(len(electrodes_from_listing),n_roots,100)\n",
    "    print(roots_simulation_to_tensor.size())\n",
    "\n",
    "    ## Calculate recruitment ##\n",
    "    # Loop through the monopolar EM simulations ( all the electrodes)\n",
    "    for i_sim in range(n_monopolar_sims):\n",
    "        sim_i=electrodes_from_listing[i_sim]\n",
    "        # Get the results for this particular simulation (=particular electrode)\n",
    "        df_neuron_sim_emSim_i=df_neuron_sim[df_neuron_sim['EM_Sim']==sim_i]\n",
    "        # Get the min and max titration factors for this Neuron simulation\n",
    "        min_trit_factor_sim_i=np.min(df_neuron_sim_emSim_i['Titration Factor'])\n",
    "        max_trit_factor_sim_i=np.max(df_neuron_sim_emSim_i['Titration Factor'])\n",
    "        \n",
    "        # Form the array of titration factors\n",
    "        trit_array_sim_i=np.linspace(min_trit_factor_sim_i,max_trit_factor_sim_i,n_data_points) # n_data_points=100\n",
    "        # Loop through the simulated roots (all roots (L1 - T12))\n",
    "        for i_root in range(n_roots):\n",
    "            root_i=roots[i_root]\n",
    "            # Get the results for this particular root for this particular simulation (5 rootlets for roots, 10 fibres per rootlet (=50 data points))\n",
    "            df_neuron_sim_emSim_i_root_i=df_neuron_sim_emSim_i[df_neuron_sim_emSim_i['Root']==root_i] \n",
    "        \n",
    "            ## Compute the recruitment\n",
    "            # Only get the titration factor\n",
    "            trit_factors_sim_i_root_i=df_neuron_sim_emSim_i_root_i['Titration Factor']\n",
    "            # Prepare the results array\n",
    "            recruitment_sim_i_root_i=np.zeros(np.shape(trit_array_sim_i)) \n",
    "            n_fibers_in_sim_i_root_i=len(trit_factors_sim_i_root_i) # 50, 5rootlets a 10 fibers\n",
    "\n",
    "            # Loop through values of titration between the min and the max of the sim\n",
    "            # activation can be 0 bc min value might be in a different root\n",
    "            # min sim is equals no activation max sim equals max\n",
    "            for i_trit in range(n_data_points): # Number of points which represents the \"amplitude\"\n",
    "                trit_i=trit_array_sim_i[i_trit]\n",
    "                # For a specific root, how many rootlets are activated at certain level (= titration factor) ?\n",
    "                n_active_trit_i= (df_neuron_sim_emSim_i_root_i['Titration Factor'] <= trit_i).sum()\n",
    "                # print(n_active_trit_i)\n",
    "                recruitment_sim_i_root_i[i_trit]=n_active_trit_i\n",
    "\n",
    "            # Prepare the output csv\n",
    "            d_rec_emSim_i_root_i = {'Trit_Array': trit_array_sim_i, 'Recruitment': recruitment_sim_i_root_i}\n",
    "            df_recruitment_emSim_i_root_i = pd.DataFrame(data=d_rec_emSim_i_root_i)\n",
    "            df_recruitment_emSim_i_root_i['Root']=root_i\n",
    "            df_recruitment_emSim_i_root_i['EM_Sim']=sim_i\n",
    "            spinal_level_df_fiber_i=\"\"\n",
    "            quadrant_df_fiber_i=\"\"\n",
    "            for spinal_level_i in spinal_levels:\n",
    "                if spinal_level_i in root_df_fiber_i:\n",
    "                    spinal_level_df_fiber_i=spinal_level_i\n",
    "                    break\n",
    "            df_recruitment_emSim_i_root_i['Spinal_Level']=spinal_level_df_fiber_i\n",
    "            for quadrant_i in quadrants:\n",
    "                if quadrant_i in root_df_fiber_i:\n",
    "                    quadrant_df_fiber_i=quadrant_i\n",
    "                    break\n",
    "            df_recruitment_emSim_i_root_i['Quadrant']=quadrant_df_fiber_i\n",
    "            \n",
    "            ## save in a tensor\n",
    "            # electrode, root, reccruitment\n",
    "            roots_simulation_to_tensor[i_sim, i_root,:]=torch.tensor(df_recruitment_emSim_i_root_i['Recruitment'].values)\n",
    "\n",
    "            ## Additional ways of saving ##\n",
    "            # save create a class to save it as pickle file instead\n",
    "            recruitment_simulation[f\"_{electrodes_from_listing[i_sim]}_{roots[i_root]}\"] = df_recruitment_emSim_i_root_i\n",
    "        \n",
    "\n",
    "    ## Dump files \n",
    "    #turn into df\n",
    "    df_electrodes_for_roots= pd.DataFrame(electrodes_from_listing, columns =['electrode_name'])\n",
    "    # save as csv\n",
    "    df_electrodes_for_roots.to_csv(location_data_dump+'df_electrodes_for_roots.csv')\n",
    "    # list version ; electrodes_from_listing\n",
    "    \n",
    "    #turn into df\n",
    "    df_roots=pd.DataFrame(roots, columns =['root_name'])\n",
    "    # save as csv                                       \n",
    "    df_roots.to_csv(location_data_dump+'df_roots.csv')\n",
    "    # list version ; roots\n",
    "\n",
    "    # dump pickle file\n",
    "    fh = open(location_data_dump+'roots_simulation_to_tensor'+'_'+subject+'.pkl', \"wb\")\n",
    "    pickle.dump(roots_simulation_to_tensor, fh)\n",
    "    fh.close()\n",
    "    fh = open(location_data_dump+'roots_simulation_as_dict'+'_'+subject+'.pkl', \"wb\")\n",
    "    pickle.dump(recruitment_simulation, fh)\n",
    "    fh.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('projectome_finder')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "f932c8e077b341d20504a7add15d58d55a3a6203500067dcddea991ea8b4378e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
